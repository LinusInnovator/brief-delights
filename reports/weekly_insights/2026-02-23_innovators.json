{
  "date": "2026-02-23",
  "segment": "innovators",
  "trends": {
    "categories": {
      "AI & Machine Learning": 2,
      "AI Research & Labs": 2,
      "Emerging Tech": 2,
      "AI & Innovation": 1,
      "Academic Research": 1,
      "Management & Leadership": 1,
      "Developer Tools & Platforms": 1,
      "Cloud & Infrastructure": 1,
      "Engineering Blogs": 1,
      "Venture Capital & Funding": 1
    },
    "sources": {
      "MachineLearningMastery.com": 2,
      "Google DeepMind News": 2,
      "AI News & Artificial Intelligence | TechCrunch": 2,
      "WIRED": 1,
      "Computer science : nature.com subject feeds": 1,
      "MIT Sloan Management Review": 1,
      "The Fly Blog": 1,
      "HashiCorp Blog": 1,
      "Stripe Blog": 1,
      "Sequoia Capital": 1
    },
    "topics": [
      "Export Your ML Model in ONNX Format",
      "Agent Evaluation: How to Test and Measure Agentic AI Performance",
      "Empowering YouTube creators with generative AI",
      "Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more",
      "UAE\u2019s G42 teams up with Cerebras to deploy 8 exaflops of compute in India",
      "Code Metal Raises $125 Million to Rewrite the Defense Industry\u2019s Code With AI",
      "A data-efficient foundation model for porous materials based on expert-guided supervised learning",
      "Connecting Language and (Artificial) Intelligence: Princeton\u2019s Tom Griffiths",
      "GPUs on Fly.io are available to everyone!",
      "The risks of cybersecurity tool sprawl: Why consolidation is a strategic priority",
      "Create new monetization opportunities with Stripe Billing\u2019s recent upgrades",
      "Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams",
      "An AI coding bot took down Amazon Web Services",
      "OpenAI says 18- to 24-year-olds account for nearly 50% of ChatGPT usage in India"
    ],
    "total_articles": 14
  },
  "article_count": 14,
  "articles": [
    {
      "id": "fbf9b038b0c6fa1abfdaf5ebff289d33",
      "title": "Export Your ML Model in ONNX Format",
      "url": "https://machinelearningmastery.com/export-your-ml-model-in-onnx-format/",
      "published_date": "2026-02-23T08:54:40.739981",
      "description": "When building machine learning models, training is only half the journey.",
      "source": "MachineLearningMastery.com",
      "category": "AI & Machine Learning",
      "segment": "builders",
      "source_type": "secondary",
      "raw_content": "When building machine learning models, training is only half the journey.",
      "tier": "full",
      "selection_reason": "Breakthrough in ML model standardization and deployment",
      "audience_value": "Critical knowledge for deploying ML models across platforms",
      "urgency_score": 9,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "8cfbe6a77c6fa3f8fe1f543805dce736",
      "title": "Agent Evaluation: How to Test and Measure Agentic AI Performance",
      "url": "https://machinelearningmastery.com/agent-evaluation-how-to-test-and-measure-agentic-ai-performance/",
      "published_date": "2026-02-23T08:54:40.739956",
      "description": "AI agents that use tools, make decisions, and complete multi-step tasks aren't prototypes anymore.",
      "source": "MachineLearningMastery.com",
      "category": "AI & Machine Learning",
      "segment": "builders",
      "source_type": "secondary",
      "raw_content": "AI agents that use tools, make decisions, and complete multi-step tasks aren't prototypes anymore.",
      "tier": "full",
      "selection_reason": "Essential framework for evaluating AI agent performance",
      "audience_value": "Practical metrics for measuring AI agent effectiveness",
      "urgency_score": 9,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "276676c1bc916da7ba7371335c64087c",
      "title": "Empowering YouTube creators with generative AI",
      "url": "https://deepmind.google/blog/empowering-youtube-creators-with-generative-ai/",
      "published_date": "2026-02-23T08:54:50.308642",
      "description": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
      "source": "Google DeepMind News",
      "category": "AI Research & Labs",
      "segment": "innovators",
      "source_type": "primary",
      "raw_content": "New video generation technology in YouTube Shorts will help millions of people realize their creative vision",
      "tier": "full",
      "selection_reason": "Major AI integration in content creation platform",
      "audience_value": "Understanding next-gen AI content generation capabilities",
      "urgency_score": 9,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "eddadc9a8ee16bb0d4f595e977e6f25e",
      "title": "Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more",
      "url": "https://deepmind.google/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/",
      "published_date": "2026-02-23T08:54:50.308622",
      "description": "We\u2019re releasing two updated production-ready Gemini models",
      "source": "Google DeepMind News",
      "category": "AI Research & Labs",
      "segment": "innovators",
      "source_type": "primary",
      "raw_content": "We\u2019re releasing two updated production-ready Gemini models",
      "tier": "full",
      "selection_reason": "Critical update to leading AI model platform",
      "audience_value": "Access to improved AI models and reduced costs",
      "urgency_score": 10,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "97b504d19a217dd5ddc4c4d75cc905b5",
      "title": "UAE\u2019s G42 teams up with Cerebras to deploy 8 exaflops of compute in India",
      "url": "https://techcrunch.com/2026/02/20/uaes-g42-teams-up-with-cerebras-to-deploy-8-exaflops-of-compute-in-india/",
      "published_date": "2026-02-23T08:54:55.404324",
      "description": "Abu Dhabi-based tech company G42 has partnered with U.S.-based chipmaker Cerebras to deploy 8 exaflops of compute through a new system in India.",
      "source": "AI News & Artificial Intelligence | TechCrunch",
      "category": "Emerging Tech",
      "segment": "innovators",
      "source_type": "secondary",
      "raw_content": "Abu Dhabi-based tech company G42 has partnered with U.S.-based chipmaker Cerebras to deploy 8 exaflops of compute through a new system in India.",
      "tier": "full",
      "selection_reason": "Major AI compute infrastructure deployment",
      "audience_value": "Insight into large-scale AI computing trends",
      "urgency_score": 9,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "292b5d53960c1c3e73cb1c75abfb5df8",
      "title": "Code Metal Raises $125 Million to Rewrite the Defense Industry\u2019s Code With AI",
      "url": "https://www.wired.com/story/vibe-coding-startup-code-metal-raises-series-b-fundraising/",
      "published_date": "2026-02-23T08:54:35.651112",
      "description": "The Boston startup uses AI to translate and verify legacy software for defense contractors, arguing modernization can\u2019t come at the cost of new bugs.",
      "source": "WIRED",
      "category": "AI & Innovation",
      "segment": "leaders",
      "source_type": "secondary",
      "raw_content": "The Boston startup uses AI to translate and verify legacy software for defense contractors, arguing modernization can\u2019t come at the cost of new bugs.",
      "tier": "full",
      "selection_reason": "AI-driven legacy code modernization breakthrough",
      "audience_value": "Novel approach to modernizing critical infrastructure",
      "urgency_score": 8,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "ce392b35fc23ee133415e7767eb10b41",
      "title": "A data-efficient foundation model for porous materials based on expert-guided supervised learning",
      "url": "https://www.nature.com/articles/s41467-026-69245-y",
      "published_date": "2026-02-23T08:54:52.582969",
      "description": "",
      "source": "Computer science : nature.com subject feeds",
      "category": "Academic Research",
      "segment": "innovators",
      "source_type": "primary",
      "raw_content": "",
      "tier": "full",
      "selection_reason": "Novel AI application in materials science",
      "audience_value": "Cross-domain AI application insights",
      "urgency_score": 8,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "eecbbbfa60a2d5f005f763fb85561f57",
      "title": "Connecting Language and (Artificial) Intelligence: Princeton\u2019s Tom Griffiths",
      "url": "https://sloanreview.mit.edu/audio/connecting-language-and-artificial-intelligence-princetons-tom-griffiths/",
      "published_date": "2026-02-23T08:54:33.209449",
      "description": "In this bonus episode of the Me, Myself, and AI podcast, Princeton University professor and artificial intelligence researcher Tom Griffiths joins host Sam Ransbotham to unpack The Laws of Thought, his new book exploring how math has been used for centuries to understand how minds \u2014 human and machine \u2014 actually work. Tom walks through [&#8230;]",
      "source": "MIT Sloan Management Review",
      "category": "Management & Leadership",
      "segment": "leaders",
      "source_type": "secondary",
      "raw_content": "<p></p>\n<p>In this bonus episode of the <cite>Me, Myself, and AI</cite> podcast, Princeton University professor and artificial intelligence researcher Tom Griffiths joins host Sam Ransbotham to unpack <cite>The Laws of Thought</cite>, his new book exploring how math has been used for centuries to understand how minds \u2014 human and machine \u2014 actually work. Tom walks through three main frameworks shaping intelligence today \u2014 rules and symbols, neural networks, and probability \u2014 and he explains why modern AI only makes sense when you see how those pieces fit together. The conversation connects cognitive science, large language models, and the limits of human versus machine intelligence. Along the way, Tom and Sam dig into language, learning, and what humans still do better \u2014 like judgment, curation, and metacognition.</p>\n<aside class=\"callout-info\">\n<img alt=\"Tom Griffiths\" src=\"https://sloanreview.mit.edu/wp-content/uploads/2025/12/MMAI-S12-BONUS1-Griffiths-Princeton-headshot-600.jpg\" /></p>\n<h4>Tom Griffiths, Princeton University</h4>\n<p>Tom Griffiths is the author of the new book <cite>The Laws of Thought: The Quest for Mathematical Theory of the Mind</cite> and the Henry R. Luce Professor of Information Technology, Consciousness, and Culture at Princeton University. He also directs Princeton\u2019s Computational Cognitive Science Lab, a research group focused on understanding the mathematical foundations of human cognition, and the Princeton Laboratory for Artificial Intelligence, which supports innovative research efforts in AI and related fields. Griffiths coauthored the book <cite>Algorithms to Live By</cite>, and his award-winning research has been published in <cite>Science</cite>, <cite>Nature</cite>, and the <cite>Proceedings of the National Academy of Sciences</cite>.</p>\n</aside>\n<p>Subscribe to <cite>Me, Myself, and AI</cite> on <a href=\"https://podcasts.apple.com/us/podcast/me-myself-and-ai/id1533115958\" rel=\"noopener\" target=\"_blank\">Apple Podcasts</a> or <a href=\"https://open.spotify.com/show/7ysPBcYtOPVgI6W5an6lup\" rel=\"noopener\" target=\"_blank\">Spotify</a>.</p>\n<h4>Transcript</h4>\n<p><strong>Allison Ryder:</strong> Hi, everyone. While we\u2019re on winter break, we\u2019re dropping a couple of bonus episodes featuring cutting-edge academic researchers. On today\u2019s episode, Sam is joined by professor and director of Princeton\u2019s Computational Cognitive Science Lab, Tom Griffiths. Tom is the author of the forthcoming book <cite>The Laws of Thought</cite> and joins Sam today to speak about AI\u2019s mathematical and linguistic backgrounds. It was a fascinating conversation, and I hope you enjoy it. </p>\n<p><strong>Tom Griffiths:</strong> I\u2019m Tom Griffiths from Princeton University, and you\u2019re listening to <cite>Me, Myself, and AI</cite>. </p>\n<p><strong>Sam Ransbotham:</strong> Welcome to <cite>Me, Myself, and AI</cite>, a podcast from <cite>MIT Sloan Management Review</cite> exploring the future of artificial intelligence. I\u2019m Sam Ransbotham, professor of analytics at Boston College. I\u2019ve been researching data, analytics, and AI at <cite>MIT SMR</cite> since 2014, with research articles, annual industry reports, case studies, and now 12 seasons of podcast episodes. In each episode, corporate leaders, cutting-edge researchers, and AI policy makers join us to break down what separates AI hype from AI success.</p>\n<p>Hi, listeners. Thanks, everyone, for joining us again. Our guest today is Tom Griffiths, professor of psychology and computer science, and the director of the Princeton Laboratory for Artificial Intelligence. Tom has a new book, <cite>The Laws of Thought</cite>, which I suspect our listeners will enjoy learning about. Tom, [it\u2019s] great to have you on the podcast.</p>\n<p><strong>Tom Griffiths:</strong> Thanks, Sam. [It\u2019s] great to be here. </p>\n<p><strong>Sam Ransbotham:</strong> Why don\u2019t we start with \u2026 I think people know it\u2019s kind of fun to be your professor because people know what professors are, but maybe let\u2019s start with a little bit of a bio. Can you give us some background on what your roles are with the lab at Princeton? </p>\n<p><strong>Tom Griffiths:</strong> Princeton, like a lot of other educational institutions, has been trying to figure out how to respond to all of the things that are happening with AI in the world at the moment. The AI lab is the starting point for doing that in terms of thinking about being able to make some targeted investments in research areas where we see potential for [a] transformative impact for AI in a way that\u2019s maybe more nimble than a traditional academic institution might. </p>\n<p><strong>Sam Ransbotham:</strong> There\u2019s a lot going on within universities trying to figure out what exactly all this means, and I guess all of society. But let\u2019s start with <cite>The Laws of Thought</cite>. Can you explain in some simple terms what these laws are and how they relate to human cognition and artificial intelligence? </p>\n<p><strong>Tom Griffiths:</strong> The idea behind the book is \u2026 I think all of us in school learn about the laws of nature, right? These [are] sort of principles of physics or something like that, that tell us about how \u2026 the world around us works. One interesting thing is that the same scientists who hundreds of years ago were trying to figure out what those laws of nature were, using math to describe the physical world, were just as interested in using math to try and understand the mental world, the world inside us. The book is really the story of that effort. </p>\n<p>It turns out understanding our inside world is a bit harder than understanding our outside world. It took us a little bit longer to figure out what the fundamental principles are. It charts the story, from people first introducing this idea of using mathematics to understand the mind, through some of the first discoveries about what kinds of mathematical principles could be used for explaining how minds work \u2014 things like mathematical logic \u2014 to the discovery that that was not going to get us all the way to understanding things like how people learn complex concepts that have fuzzy boundaries, things like languages, and then ideas like artificial neural networks, which are very popular at the moment in artificial intelligence, and then probability and statistics as another approach that really helps us understand why it is that some of those AI methods actually work. </p>\n<p><strong>Sam Ransbotham:</strong> I think you approach this from three different frameworks: rules and symbols is one framework, neural networks is another, and then Bayesian probability is a third. Maybe I\u2019m grossly oversimplifying these three big prongs in the book. Maybe take a minute and explain what each of those pieces are and then, more importantly, how they all weave together. </p>\n<p><strong>Tom Griffiths:</strong> You got it. Those are the three big pieces. Basically the story is that I think the origins of people trying to think about mathematical principles for understanding the mind are really tied up in that rules and symbols approach. That was because that seemed like the first tool that we had that really described something like how thought worked. So if you go back to the origins of logic, the title of the book, <cite>The Laws of Thought</cite>, is a phrase that\u2019s used by George Boole, who was working in the 19th century and sort of figured out some of the first principles of mathematical logic. </p>\n<p>Those principles turned into the principles that underlie our computers today, through the work of Alan Turing and John von Neumann and others. When psychologists were trying to work out how to rigorously study something that you can\u2019t see or touch \u2014 something inside our heads, our minds \u2014 they discovered that those mathematical principles of logic were actually really useful for expressing rigorous, precise hypotheses about how minds work. So that was the starting point for what we now call cognitive science, which is trying to use these mathematical principles to figure out how minds work. </p>\n<p>For a while it seemed like that was going pretty well. It turned out that those systems of rules and symbols worked well for describing things like deductive reasoning, things like problem-solving or planning, things like even the structure of languages through the work of people like Noam Chomsky. But after a while they started to realize that maybe that wasn\u2019t going to be all that we\u2019d need in order to understand how minds work. </p>\n<p>One of the big problems for that rules and symbols approach was explaining learning. It helps us to explain how we reason, helps us to explain what the structures or languages are like, but it doesn\u2019t help us to explain how those things get into our heads in the first place. How do we learn these kinds of strategies for thinking? How do we learn what the structure of those languages are? And it also didn\u2019t work for capturing some of the \u2026 fuzzy boundaries that we see in real concepts. \u2026 If you ask people, \u201cIs an olive a fruit?\u201d people are quite uncertain about [the answer] in a way that\u2019s maybe hard to capture if you\u2019re really just thinking in terms of something like logic. </p>\n<p>In the 1960s-1970s, people started to explore different ways of thinking about the mind in terms of different kinds of mathematics, and thinking about things like maybe our concepts are related to \u2026 we can think about something in the world as being a point in space, where it\u2019s an abstract space that picks out the features that thing has. Maybe a concept is a region in that space. Now a new kind of mathematics is needed for describing these kinds of continuous representations. </p>\n<p>It turns out that when you start thinking in those terms, you end up getting to new ways of thinking about how to solve that learning problem. And that\u2019s where artificial neural networks come in. They\u2019re essentially a way of thinking about how to represent things as points in space and then learn the relationships between those points in space so you can map from one space to another. So that solved a bunch of problems that we had for logic. </p>\n<p>But then we have a bunch of other questions. For example, if we look at things like our large language models [LLMs] today that are very successful in doing all sorts of things like learning language. Really understanding why it is that they\u2019re able to do that requires us to take one more step and think about a different kind of mathematical idea. [Those] ideas come from probability and statistics. Statistics is really the science of inductive inference. It tells us what we can infer from data, and probability theory gives us a tool for understanding how we can work with uncertainty and how we can make inferences from the data that we see. </p>\n<p><strong>Sam Ransbotham:</strong> Is there a fourth one? We\u2019ve got three nice things, and each time you pointed out some aspect of them that [was] strong, and some aspect that led to a limitation. Is there [a] number four out there that we need that we haven\u2019t figured out yet? Or is it just a matter of getting these three mixed in the right proportions and emphasized in the right ways? </p>\n<p><strong>Tom Griffiths:</strong> I think these three are actually pretty good. \u2026 A funny thing that happened to me when I was writing this book is that I\u2019ve been teaching these kinds of ideas to undergraduates for 20 years. When I give my class on computational approaches to understanding cognition, I would normally start that class by saying, \u201cUnlike taking a class in physics or something like that, where you can expect to hear the answers, we\u2019re still figuring these things out. We have good ways of asking the questions [even though] we haven\u2019t quite \u2026 got to those answers.\u201d But I actually think in the last 10 years, in the period that I was working on the book, I think there\u2019s been a change in how much we understand about these things and how well they fit together. We can kind of start to see some glimmers of really figuring out what those laws of thought might look like. </p>\n<p><strong>Sam Ransbotham:</strong> [Are these] laws of thought going to be understanding the borders between these better, or is it going to be some sort of complementarity between them, or some sort of combination in a unique way? </p>\n<p><strong>Tom Griffiths:</strong> Complementarity and combination are, I think, the two ways to think about this. One thing that we\u2019ve started to realize is that there [are] different ways that you can provide an explanation for something like the human mind. So, again, if you\u2019re a physical scientist and you want to explain a phenomenon, say, the behavior of an animal, you could think about explaining that phenomenon at lots of different levels. You could explain it in terms of the environment that the animal is in. You could explain it in terms of the muscles and bones of the animal that are doing certain kinds of things and the nerves and so on. You could explain it in terms of the chemical reactions that are happening to produce those things, or you could explain it in terms of the atoms and molecules that are interacting. There are all of these different levels of analysis that we\u2019re used to thinking about when we think about physical systems. </p>\n<p>One of the insights of cognitive science, something that goes back to a theoretical neuroscientist called David Marr, is the idea that there are similar kinds of levels of analysis that we can think about when we\u2019re trying to understand something like human behavior or the behavior of an intelligent system more generally. </p>\n<p>Marr suggested you could think about this in terms of three levels. The most abstract is what he called the computational level, which is: What\u2019s the abstract problem the system is solving, and what does the solution to that problem look like? And then, more concrete than that, there\u2019s what\u2019s called the algorithmic level, which is: What are the actual processes that are going on inside that system? What [are] the algorithms that are being executed to produce that solution? Then the third is what\u2019s called the implementation level, which is: How is that algorithm implemented inside the brain? </p>\n<p>One important insight here is that these three different systems of mathematics that we\u2019ve been talking about don\u2019t need to be fighting with one another. They can be cooperating by giving us explanations that operate at different levels of analysis. In particular, logic and probability theory are at that most abstract level. They kind of describe how an ideal agent should solve problems that [it] faces, problems like, how do I figure out what\u2019s true based on the things that I already know? Or what inferences can I draw from the things that I\u2019ve seen already? </p>\n<p>The neural networks give us a story about how you can actually create systems that implement different kinds of algorithms that are strategies for approximating solutions to those more abstract, more idealized kinds of mathematical systems. </p>\n<p>So part of the reason why I think maybe three is enough is that logic tells us how to solve what we call deductive problems, problems that require figuring out what\u2019s true when we have all the information. Probability theory tells us how to solve what are called inductive problems, problems where we don\u2019t have all the information and we have to kind of do the best we can to figure out what to do based on what we know. And then our brains somehow solve both of those kinds of problems using things that look very much like the kinds of structures of artificial neural networks. So that combination of three things actually gives us ways of describing the abstract problems we solve as well as the kinds of physical systems that might actually implement solutions to those problems. </p>\n<p><strong>Sam Ransbotham:</strong> Language is a pervasive idea through the book. We can give a nod to my frequent coauthor David Kiron, who\u2019s super into [Ludwig] Wittgenstein and \u201cIf you can\u2019t express it in language, it doesn\u2019t exist\u201d type of ideas. It\u2019s a major function of the book. </p>\n<p>What\u2019s the relationship between maybe the fact that we\u2019re coming up with all this in a moment of English language dominance and would all these things be the same if we\u2019d had them 200 years ago with a French language dominance? We, at the same time, have another layer of mathematical language, which is pervasive. Is coding language another one of these languages that is going to be pervasive? How do all these connections between language and intelligence link up in your mind?</p>\n<p><strong>Tom Griffiths:</strong> Language is a recurring example because it has characteristics that line up with all of these three kinds of mathematical ways of thinking about minds. So the rules and symbols part is what you can think about in terms of a traditional \u2026 way of thinking about grammar in language: A sentence has a noun and a verb, and you know they\u2019re combined in particular ways, and you can move them around in certain kinds of ways. That was this sort of important insight that Noam Chomsky had that really organized most of 20th century linguistics and continues to influence the way people think about these things. </p>\n<p>But that is not enough to explain everything that happens involving language. One of the challenges that Chomsky had was explaining how it is that human children come to speak language, because there wasn\u2019t really a good way to formalize learning in that rules and symbols approach. So he ended up concluding you just had to build it all in. And then, based on the limited information you get, you\u2019ve got enough constraints in the system that the right thing comes out. </p>\n<p>Neural networks offered a way to think about how you could learn things like language from data by showing that even if you had something that was described by a system of rules and symbols, it didn\u2019t need to be implemented as a system of rules and symbols. Some of the key insights that came from [the] early work [of] using neural networks were that you could take grammar and you could have a neural network learn that grammar. It could do so without ever having explicitly represented a noun or a verb or any of those kinds of things. So that gives us a different way of thinking about what language is and a way of understanding how it is that languages might be learned. </p>\n<p>And then, probability theory helps us to understand how, in general, we could imagine those processes of learning working, and sort of understand what it is that they do. So if we think about what language is, it also has this inductive component, where when I say something, you\u2019re trying to figure out what I\u2019m trying to communicate to you, and you\u2019re making an inference from the things that are coming out of my mouth in order to know what\u2019s going on. And your brain is also trying to solve a prediction problem, where it\u2019s trying to cue up, \u201cWhat are the concepts that are likely to come up in this conversation next?\u201d in a way that makes it easy for you to understand the things that we\u2019re saying. </p>\n<p>So if you think about language as a probabilistic object, then we can understand some of the things about how it works and how it\u2019s learned in a way that goes beyond just how we might actually be able to create something like a neural network that instantiates that language. </p>\n<p>When we look at things like large language models, I think they\u2019re actually a great illustration of how these three things come together. First of all, in order to create these systems [that] are able to demonstrate a remarkable amount of intelligence, we need to train them on something [that] has this kind of rules and symbols structure. Large language models aren\u2019t just trained on natural language, and they\u2019re not just trained on English. So you get trained on English. You get trained on French. They also get trained on a large amount of computer code. They\u2019re getting a lot of symbolic structure built into them through that training process. And that\u2019s part of what underlies the intelligence that they manifest. They\u2019re based on these big artificial neural networks. So that\u2019s that second piece. That\u2019s the reason why it\u2019s possible to learn those things. </p>\n<p>And then the third piece is the way that they\u2019re trained is by predicting the next token [that] is going to appear in a sequence, the next word or part of a word that they\u2019re going to see based on all of the words, the parts of words that they\u2019ve seen before. So that training is explicitly setting this up as a probabilistic model. But what it\u2019s trying to do is to learn a probability distribution over sequences of tokens. And what it\u2019s trying to do when you\u2019re interacting with it is make inferences about what sequences of tokens you might want it to generate based on the sequences of tokens that you\u2019ve typed into it. </p>\n<p><strong>Sam Ransbotham:</strong> Let me push back though a little bit. \u2026 You mentioned the rules and symbols. It feels like that\u2019s a place where these current implementations of large language models might be a bit weak. I think one of the examples you gave in your book is that we can pick up a word from the first use, or we can even make up words that should be real words, even if they aren\u2019t really words. We do that based off of an understanding of how those symbols work and how those tokens work. \u2026 People can learn a word on their first hearing. They don\u2019t require the 14 million images of ImageNet to learn. You kind of implied that given this large corpus of knowledge, it would extract those rules and symbols. </p>\n<p>Why not push them a little bit more and give them some rules and symbols to work with? Rather than learn about gravity, you say, \u201cHey, here\u2019s gravity. This is how it works \u2014 always, not just in the four examples that you\u2019ve seen. It works that way all the time.\u201d Where\u2019s that? </p>\n<p>Maybe I\u2019ll push back a little bit to say [that] when I\u2019ve seen some examples of some of the large language models struggling with math, they\u2019ve struggled not with \u201cWhat is 2 plus 2?\u201d Because they\u2019ve seen millions of examples of that. But if you take a superlong number and add it to another superlong number, you tend to get a random, superlong, other number rather than the symbolic representation. You mentioned, I think, in one of the chapters, [that] we understand numbers without ever having seen that specific number before. Is there room for more symbolic processing here, [a] more rules-based approach? </p>\n<p></p>\n<p><strong>Tom Griffiths:</strong> Yeah. I think you highlighted two of the important ways in which current AI systems differ from human cognition, and two of the kinds of things where we can imagine learning things from how human minds work that might make those AI systems better. So those two things [involve] generalization \u2014 being able to generalize in a systematic way beyond the data that they\u2019re provided and learning from small amounts of data. </p>\n<p>I gave the example of kids learning language. A kid learns language on the order of 10 years, whereas the kinds of large language models that are deployed today require more on the order of 10,000 years of continuous speech or something like that in order to reach the level of competence that they reach. </p>\n<p>So those are places where we have opportunities to learn from people. The first of those, this point about generalization, is really about have you formed the right kinds of representations of a domain such that when you start to see things that go beyond the training data you\u2019ve seen, you\u2019re able to then respond to those in ways that are consistent with what you should have learned, in order to represent the domain that you\u2019re operating in? That remains an outstanding problem for language models. </p>\n<p>Part of the way that they\u2019re able to do this is they\u2019ve been exposed to so much linguistic data that they\u2019re able to do very well without necessarily needing to do a lot of extrapolation beyond the kinds of data that they\u2019ve seen before. I have colleagues who have developed paradigms for measuring the extent to which they can extrapolate. They can actually do fairly well. You can do things like have them compose ideas together that they\u2019ve not encountered before and come up with new kinds of things when you put those pieces together. But I think that\u2019s something where there are still limitations in the systematicity of generalization. </p>\n<p>One of the things that surprises us about large language models is they sometimes behave in ways that make very little sense to us. That\u2019s because we\u2019re expecting them to generalize in ways that are like the ways that we\u2019re used to human beings generalizing. The other part of that, the learning part, I think, is perhaps one of the keys to thinking about how we can make systems that generalize better. Because being able to learn from less data very much requires being able to engage in good systematic generalizations. The way we talk about that in machine learning and in cognitive science is in terms of what we call inductive bias. </p>\n<p>Inductive bias is what the learner brings to a problem. That means that they favor some solutions over others. So if you see only a limited amount of data, there are many possible ways that you could explain [the] data that you saw. How do you choose between those many possible explanations? If you\u2019re learning a language, how do you choose which structure of the language you\u2019re going to infer?</p>\n<p>Inductive bias is the thing that breaks ties there. It tells us, \u201cYou should think about it this way rather than this way.\u201d Humans undoubtedly have a systematic set of inductive biases that are not instantiated in our neural networks. One of the important challenges for both AI and cognitive science is figuring out what those human inductive biases are and figuring out how to put them into things like these kinds of neural network systems. That\u2019s something that I work on in my lab. It\u2019s something that a lot of cognitive scientists are actively thinking about at the moment. </p>\n<p><strong>Sam Ransbotham:</strong> One of the things I enjoyed was with each chunk in your book, you take a little bit of a historical path through how we got to this point. You mentioned before Boole and the development of Boolean logic and Bayes, and how that added to the equation. Now I\u2019m going to be mean here and say that \u201cOK, these are some summaries of historical information leading to a path.\u201d My mean part is, \u201cWhat did you, Tom the human, add to this book?\u201d </p>\n<p>Were I to summarize the development of language or the development of Bayesian thought or probabilistic reasoning, and I put that in an LLM, and I ask, \u201cGive me four paragraphs about that.\u201d What did you the human add to this equation, to this book that would not have been done by that summarization process? </p>\n<p><strong>Tom Griffiths:</strong> There are a couple of things. One thing is the book actually involves a lot of primary source research. The story of where the book came from is partly that I realized that our field of cognitive science is one where, at the time when I started this project, many of the people who were there at the sort of birth of modern cognitive science in the 1950s were still alive, and I was able to go around and interview them and collect their stories. So a lot of the book is really telling those stories and using those to explain where those ideas come from. </p>\n<p>But in terms of the writing, I think the thing that I am able to do as a human author is engage in what we call theory of mind in cognitive science. This is me thinking about what it is that is going to make sense to a reader and that\u2019s going to be appealing, not just as a story but also clear in terms of conveying those ideas and putting those together in a structure that makes sense for the reader. I\u2019m not going to claim that\u2019s something only humans are going to be able to do forever. I think, at the moment, it\u2019s something that still humans are better at doing than the current models that we have. But we actually have been doing experiments in my lab and showing that large language models are not bad at putting together a curriculum for people to help them learn a concept, sort of figuring out, \u201cYou need to introduce this simpler idea first and then this other idea, and then it can put them together and so on.\u201d So they\u2019re definitely able to extract some of the structures that we use for solving these problems through our own intuitions about pedagogy and theory of mind and so on. </p>\n<p><strong>Sam Ransbotham:</strong> Maybe a different thing is that there [are] a lot of stories that you didn\u2019t include in the book. There\u2019s a lot of curation that\u2019s happening. That\u2019s one thing that I guess I\u2019m thinking about a lot. We have the machines capable of [having] effectively infinite memory of all possible stories. There\u2019s definitely value in you stitching out and saying, \u201cThese were important for this reason, and this is important for another reason,\u201d because these were some big steps. In doing so you\u2019ve inherently had to leave out some things. There\u2019s a curation going on there. I feel like that\u2019s something that you knew what to focus on that was important for the story, and maybe, like you say, the machines aren\u2019t quite there for that. </p>\n<p><strong>Tom Griffiths:</strong> This is actually, I think, a good connection to a question that I get asked a lot: What\u2019s going to happen to the kinds of jobs that humans do? Because we\u2019ve previously seen technology replace certain kinds of labor \u2014 physical labor [of] various kinds, manufacturing, things like that. And now we\u2019re seeing machines start to replace cognitive labor, which is different. </p>\n<p>As a psychologist, one of the things that I think about is there\u2019s another kind of labor that maybe is going to become even more important, which is metacognitive labor. This is what you\u2019re doing as a manager when you\u2019re thinking about, \u201cWho is going to be the best employee to do this job, and how should I describe it to them in order to ask them to do it so that it ends up being done in a way that\u2019s effective?\u201d Or thinking about for yourself: \u201cWhat strategy should I use to solve a problem?\u201d and \u201cWhat\u2019s the right way to approach this problem?\u201d</p>\n<p>What we\u2019re starting to do with these machines is outsource the cognitive component of the work. They\u2019re able to do some of that for us, but we\u2019re still having to do a lot of the metacognitive part. So that curation process you\u2019re describing is a good example of something [that] is not telling the story; it\u2019s figuring out the structure around that. That\u2019s going to be the analogs of the prompt that you\u2019d be providing to the AI system to maybe tell that story for you. </p>\n<p><strong>Sam Ransbotham:</strong> Are there other things besides metacognition? What else is in that list? </p>\n<p><strong>Tom Griffiths:</strong> The first thing, I would say, is metacognition is quite a big item. I\u2019m giving it the same status as physical labor and cognition. There are lots of people today whose jobs are metacognitive jobs, in management roles. And I think that\u2019s going to be a skill set that becomes more and more important. </p>\n<p>One of the things that happens in graduate school \u2014 well at least when I work with my graduate students \u2014 is not just learning how to do research but also learning how to think about what a good research project is. What I say to my students is there\u2019s a difference between the projects that we could do and the projects that we should do. Figuring out how to prioritize and work out what the best ideas are [is] one of the hardest things for people to learn, and that\u2019s part of why it takes quite a long time to do a Ph.D. I think that kind of skill set is going to be one that becomes increasingly valuable as it becomes easier to execute on these kinds of things. </p>\n<p><strong>Sam Ransbotham:</strong> One of the things that you mentioned and others have mentioned, too, is some of these constraints that are constraints on human intelligence are not the same as the constraints on machines. \u2026 What are some of those constraints [where] you see differences between machines and humans? And then what are the implications of there not being those constraints in the future? </p>\n<p><strong>Tom Griffiths:</strong> The three that I would normally highlight are: We have limited lifespans, limited time in this world. That means limited data we can learn from, limited compute. So [we have] limited cognitive resources, because we just carry around 2 or 3 pounds of neural tissue, and we have to do everything with that. </p>\n<p>And then, [we have] limited bandwidth for communication. If I want to share some of the data or compute that I have with you, I have to do it through this very inefficient mechanism that we\u2019re using right now of making honking noises. That set of constraints, I would say, [is] what makes human intelligence what it is, right? \u2026 We\u2019ve evolved minds in response to those constraints. </p>\n<p>If you look at what\u2019s going on for AI systems, really none of those things are true. We are able to turn up the knob of compute as high as it can go. It\u2019s somewhat limited at the moment because we\u2019re running out of money and energy resources to be able to keep building data centers. But that\u2019s something where the expectation that we should have is that we should, over time, continue to be able to have greater compute capacity for training the systems. That translates into being able to train systems on much more data, and all of [our] breakthrough AI systems have been trained on more data than human beings will ever experience. </p>\n<p>AlphaGo [has] many human lifetimes of playing [the] game of Go, and our language models today have many human lifetimes of linguistic data. </p>\n<p>And then bandwidth: You can take one AI system that\u2019s been trained on one set of things and then train it on some more things, or transfer the weights that it has between machines or split them up in all these ways. This idea of foundation models is that you can have one model and then copy it many times and then fine-tune those to solve different problems, and that\u2019s just fundamentally different from humans. For those reasons, I think we\u2019re going to see a meaningful divergence between the kinds of minds that humans are and the kinds of minds that the AI systems are. We shouldn\u2019t expect them to be the same because they\u2019re operating under different constraints, but we can still learn meaningful things about one another by comparing these different species when we take into account the fact that we\u2019ve evolved in these different environments. </p>\n<p><strong>Sam Ransbotham:</strong> I liked your \u201cWe communicate by making honking noises to each other.\u201d Is that holding us back? Is there a need for a language 3.0 type of a thing to move us to better bandwidth? </p>\n<p><strong>Tom Griffiths:</strong> Ren\u00e9 Descartes wrote about this idea all the way back when he was starting to think about math for the physical world. He talked about this idea that maybe there\u2019s a similar sort of structure to language. You could imagine creating a language where just hearing somebody say something in that language, you know what that thing is. </p>\n<p>In the same way that if I say \u201c10,000, 500, and 42,\u201d even though that\u2019s not a string you\u2019ve ever heard before, it tells you exactly the thing that it\u2019s referring to, you can sort of figure it out from the expression. </p>\n<p>[Gottfried] Leibniz was also obsessed with this idea. He had this idea that he called the universal character, which was a language in which you would be able to express things and then perform some mathematical operations on those things, and then figure out what the consequences of those things were. Just by expressing things in that language, you would know whether those things were true or false, and whether they were compatible with other things, and so on. That\u2019s what motivated him to think about mathematical logic. There was this spirit that traced through the book in terms of thinking about what the consequences of having these kinds of mathematical formalisms for understanding thought can be. </p>\n<p>So it\u2019s an interesting question: Can you turn all of that back around and come up with better languages for humans? There\u2019s a little bit of work along these lines. Bean Kim and colleagues at Google have a paper [that] looks at neologisms for language models, where it\u2019s looking at what are places where introducing a new term can help a language model capture a concept that\u2019s relevant to the operations that model is doing but also help us understand what it is that the language model is doing? </p>\n<p>I think you can imagine building better interfaces between us and AI systems by allowing language to evolve in ways that capture concepts that are relevant to those systems. That sounds like an interesting cognitive science problem. </p>\n<p><strong>Sam Ransbotham:</strong> We may be headed that way anyway by communicating with emojis. It doesn\u2019t convey well on this audio format, but the chapter you\u2019ve got about the representation of those universal symbols and how those worked, I didn\u2019t know about that beforehand. So I was able to pick up on that. One of the things on your website says \u2014 and I\u2019ll quote you \u2014 \u201cIt\u2019s natural to ask, \u2018What makes human intelligence special?\u2019\u201d So if it\u2019s natural, let me ask it: What makes human intelligence special? </p>\n<p><strong>Tom Griffiths:</strong> I would say those things that I mentioned, the constraints, are the things that really shape the nature of human intelligence. But I think it\u2019s maybe a mistake to think about that as being special. Rather, maybe we should think about that as being different. I think there\u2019s a tendency that people have when they talk about AI to think about intelligence being a one-dimensional scale. So people ask questions like, \u201cHave we made superintelligence?\u201d \u201cHave we made whatever the next iteration of this is?\u201d I think that\u2019s a very limited way of thinking about what it is minds are and what intelligence is. </p>\n<p>I think it\u2019s maybe better to think about intelligence as being shaped by the kinds of problems that minds have to solve and the kinds of constraints that they have to solve those problems under. That\u2019s maybe more like a sort of evolutionary way of looking at things, where we can imagine minds being shaped by those problems and constraints. But it\u2019s something where if we apply that to thinking about AI, we\u2019re going to have expectations that humans and AI systems are going to be meaningfully different. </p>\n<p>There are ways that you can imagine making AI systems better by incorporating things that come from people. That\u2019s part of what makes it exciting to think about these things from the perspective of cognitive science. But I don\u2019t think it\u2019s obligatory that we do that, because we could come up with completely different ways of solving those problems that make it possible for us to make AI systems that can do the things that we want AI systems to do, without them necessarily having to be exactly like us. </p>\n<p>I think when people talk about [artificial general intelligence] and wanting to make systems that are like people but better in whatever way, my reaction to that is to say, \u201cWell, maybe we should just think about them as being different from us but having a set of capabilities that that are perhaps harmonious with and complementary to the abilities that we have as humans.\u201d</p>\n<p>I think another thing that we should think about when we\u2019re trying to think about these differences between humans and AI systems is exactly what it is that we want to use our AI systems for. In general, we have a higher bar for the behavior of our AI systems than we have for a human being. That\u2019s appropriate, right? If we\u2019re going to be deploying a system intentionally and we could make it better, we should try and make it better. </p>\n<p>I think some of these things, like reasoning and being able to solve math problems, and so on, that are within the capacity of AI systems but are in some ways a challenge for our current large language model-based systems, are places where there\u2019s opportunities to use what people call a neuro-symbolic approach, where you build in aspects of logic or other kinds of mathematical tools that these systems can use to be able to do things that make them better than the baseline language models are. That\u2019s an important thing to do if you want to make better AI systems.</p>\n<p>It\u2019s not necessarily something that\u2019s going to help us understand human minds better. Human minds are built out of the same sort of messy stuff that we\u2019re trying to build our large language models out of and mess up in the same kinds of ways as those models when you have them solve math problems or do other kinds of things. Part of that is suggesting that, again, there\u2019s a kind of divergence that could happen where we need to do a bunch more work to figure out how to make our AI systems reliable in ways \u2026 in order to be deployable, but we have enough of the basic principles figured out that we still have good insight into human cognition already.</p>\n<p><strong>Sam Ransbotham:</strong> What I like about that is it speaks to the idea that LLMs, though wonderful, [are] not necessarily the end of the chapter of the book. There are whole different ways of approaching these problems that may or may not have strengths and weaknesses. Just like you mentioned with the growth of the different approaches, whether it\u2019s symbols and rules or Bayesian logic or neural networks, we can realize some limitations and then build on them and try to combine those in different ways. So maybe there\u2019s hope for some entirely new approaches. </p>\n<p>This is all interesting. Given these laws of thought, what should our listeners change about anything that they do tomorrow? </p>\n<p><strong>Tom Griffiths:</strong> I think one thing is it might change the way that you think about what AI systems are doing. I think we all have a model of how minds work that\u2019s based on interacting with other humans. And when we think about our AI systems, we think about them using the same set of tools that we use for thinking about other humans. And that can be \u2026 misleading in a few ways. </p>\n<p>One way is that we can have incorrect assumptions about how they\u2019re going to generalize. We say, \u201cThis AI system solved this olympiad math problem that\u2019s extremely hard.\u201d And then if we think about a human being who is able to do that, you\u2019d say, \u201cOh, they must be incredibly smart. They must be able to do all sorts of things that I can\u2019t do.\u201d But in fact, that\u2019s a relatively narrow piece of the profile of these systems. In some ways, getting better at solving these kinds of problems might make them less good at solving other kinds of problems, and there\u2019s a kind of balancing act that goes on there. </p>\n<p>So when you try and make generalizations [such as], \u201cIf this kind of machine can solve this problem, it\u2019s going to be able to solve this other problem,\u201d I think if you approach it as not something that\u2019s like us but rather something that\u2019s shaped by the way in which it\u2019s been trained and the constraints that it operates under, and all these other kinds of things, our expectations about how the systems are going to generalize would be different. So that might make you a little more pessimistic about timelines for building [artificial general intelligence], right? We shouldn\u2019t make the same generalizations from the peaks, covering the entire surface of the abilities of these systems. </p>\n<p>I think the other thing it might do is help us to imagine futures that are perhaps less scary in terms of the way that we imagine these systems affecting human societies. If we start thinking about AI systems as being different from us, then that suggests this view of complementarity, where there are going to be things that you\u2019re going to be better at, and there are going to be things the AI is going to be better at. Just like you try and figure out how to divide jobs up across people who have different kinds of abilities, thinking about how it is that we\u2019re going to divide the kinds of things that we want to be able to accomplish between humans who can do certain kinds of things and AI systems that can do other kinds of things is maybe a healthier way of thinking about this than sort of imagining that we\u2019re going to be completely replaced. </p>\n<p><strong>Sam Ransbotham:</strong> It\u2019s fascinating talking to you. We\u2019ve been talking about the <cite>Laws of Thought</cite>, which is coming out [on] Feb. 10. Tom, thanks for taking the time to talk with us today. </p>\n<p><strong>Tom Griffiths:</strong> Thank you. </p>\n<p><strong>Sam Ransbotham:</strong> Thanks for listening today. On our next episode, I\u2019ll speak with Nobel Prize-winning economist Daron Acemoglu about his research at MIT. Please join us.</p>\n<p><strong>Allison Ryder:</strong> Thanks for listening to <cite>Me, Myself, and AI</cite>. Our show is able to continue, in large part, due to listener support. Your streams and downloads make a big difference. If you have a moment, please consider leaving us an Apple Podcasts review or a rating on Spotify. And share our show with others you think might find it interesting and helpful.</p>\n<p></p>",
      "tier": "full",
      "selection_reason": "Deep dive into AI cognition research",
      "audience_value": "Understanding fundamental AI principles",
      "urgency_score": 8,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "49203b8704dd69f2cdc72cfa067ffb5b",
      "title": "GPUs on Fly.io are available to everyone!",
      "url": "https://fly.io/blog/gpu-ga/",
      "published_date": "2026-02-23T08:54:42.124516",
      "description": "<div class=\"lead\"><p>Fly.io makes it easy to spin up compute around the world, now including powerful GPUs. Unlock the power of large language models, text transcription, and image generation with our datacenter-grade muscle!</p>\n</div>\n<p>GPUs are now available to everyone!</p>\n\n<p>We know you&rsquo;ve been excited about wanting to use GPUs on Fly.io and we&rsquo;re happy to announce that they&rsquo;re available for everyone. If you want, you can spin up GPU instances with any of the following cards:</p>\n\n<ul>\n<li>Ampere A100 (40GB) <code>a100-40gb</code>\n</li><li>Ampere A100 (80GB) <code>a100-80gb</code>\n</li><li>Lovelace L40s (48GB) <code>l40s</code>\n</li></ul>\n\n<p>To use a GPU instance today, change the <code>vm.size</code> for one of your apps or processes to any of the above GPU kinds. Here&rsquo;s how you can spin up an <a href=\"https://ollama.ai\" title=\"\">Ollama</a> server in seconds:</p>\n<div class=\"highlight-wrapper group relative toml\">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-rumbg9gv\"><span class=\"py\">app</span> <span class=\"p\">=</span> <span class=\"s\">\"your-app-name\"</span>\n<span class=\"py\">region</span> <span class=\"p\">=</span> <span class=\"s\">\"ord\"</span>\n<span class=\"py\">vm.size</span> <span class=\"p\">=</span> <span class=\"s\">\"l40s\"</span>\n\n<span class=\"nn\">[http_service]</span>\n  <span class=\"py\">internal_port</span> <span class=\"p\">=</span> <span class=\"mi\">11434</span>\n  <span class=\"py\">force_https</span> <span class=\"p\">=</span> <span class=\"kc\">false</span>\n  <span class=\"py\">auto_stop_machines</span> <span class=\"p\">=</span> <span class=\"kc\">true</span>\n  <span class=\"py\">auto_start_machines</span> <span class=\"p\">=</span> <span class=\"kc\">true</span>\n  <span class=\"py\">min_machines_running</span> <span class=\"p\">=</span> <span class=\"mi\">0</span>\n  <span class=\"py\">processes</span> <span class=\"p\">=</span> <span class=\"nn\">[\"app\"]</span>\n\n<span class=\"nn\">[build]</span>\n  <span class=\"py\">image</span> <span class=\"p\">=</span> <span class=\"s\">\"ollama/ollama\"</span>\n\n<span class=\"nn\">[mounts]</span>\n  <span class=\"py\">source</span> <span class=\"p\">=</span> <span class=\"s\">\"models\"</span>\n  <span class=\"py\">destination</span> <span class=\"p\">=</span> <span class=\"s\">\"/root/.ollama\"</span>\n  <span class=\"py\">initial_size</span> <span class=\"p\">=</span> <span class=\"s\">\"100gb\"</span>\n</code></pre>\n  </div>\n</div>\n<p>Deploy this and bam, large language model inferencing from anywhere. If you want a private setup, see the article <a href=\"https://fly.io/blog/scaling-llm-ollama/\" title=\"\">Scaling Large Language Models to zero with Ollama</a> for more information. You never know when you have a sandwich emergency and don&rsquo;t know what you can make with what you have on hand.</p>\n\n<p>We are working on getting some lower-cost A10 GPUs in the next few weeks. We&rsquo;ll update you when they&rsquo;re ready.</p>\n\n<p>If you want to explore the possibilities of GPUs on Fly.io, here&rsquo;s a few articles that may give you ideas:</p>\n\n<ul>\n<li><a href=\"https://fly.io/blog/not-midjourney-bot/\" title=\"\">Deploy Your Own (Not) MidJourney Bot On Fly GPUs</a>\n</li><li><a href=\"https://fly.io/blog/scaling-llm-ollama/\" title=\"\">Scaling Large Language Models to zero with Ollama</a>\n</li><li><a href=\"https://fly.io/blog/transcribing-on-fly-gpu-machines/\" title=\"\">Transcribing on Fly GPU Machines</a>\n</li></ul>\n\n<p>Depending on factors such as your organization&rsquo;s age and payment history, you may need to go through additional verification steps.</p>\n\n<p>If you&rsquo;ve been experimenting with Fly.io GPUs and have made something cool, let us know on the <a href=\"https://community.fly.io/\" title=\"\">Community Forums</a> or by mentioning us <a href=\"https://hachyderm.io/@flydotio\" title=\"\">on Mastodon</a>! We&rsquo;ll boost the cool ones.</p>",
      "source": "The Fly Blog",
      "category": "Developer Tools & Platforms",
      "segment": "builders",
      "source_type": "primary",
      "raw_content": "<div class=\"lead\"><p>Fly.io makes it easy to spin up compute around the world, now including powerful GPUs. Unlock the power of large language models, text transcription, and image generation with our datacenter-grade muscle!</p>\n</div>\n<p>GPUs are now available to everyone!</p>\n\n<p>We know you&rsquo;ve been excited about wanting to use GPUs on Fly.io and we&rsquo;re happy to announce that they&rsquo;re available for everyone. If you want, you can spin up GPU instances with any of the following cards:</p>\n\n<ul>\n<li>Ampere A100 (40GB) <code>a100-40gb</code>\n</li><li>Ampere A100 (80GB) <code>a100-80gb</code>\n</li><li>Lovelace L40s (48GB) <code>l40s</code>\n</li></ul>\n\n<p>To use a GPU instance today, change the <code>vm.size</code> for one of your apps or processes to any of the above GPU kinds. Here&rsquo;s how you can spin up an <a href=\"https://ollama.ai\" title=\"\">Ollama</a> server in seconds:</p>\n<div class=\"highlight-wrapper group relative toml\">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-rumbg9gv\"><span class=\"py\">app</span> <span class=\"p\">=</span> <span class=\"s\">\"your-app-name\"</span>\n<span class=\"py\">region</span> <span class=\"p\">=</span> <span class=\"s\">\"ord\"</span>\n<span class=\"py\">vm.size</span> <span class=\"p\">=</span> <span class=\"s\">\"l40s\"</span>\n\n<span class=\"nn\">[http_service]</span>\n  <span class=\"py\">internal_port</span> <span class=\"p\">=</span> <span class=\"mi\">11434</span>\n  <span class=\"py\">force_https</span> <span class=\"p\">=</span> <span class=\"kc\">false</span>\n  <span class=\"py\">auto_stop_machines</span> <span class=\"p\">=</span> <span class=\"kc\">true</span>\n  <span class=\"py\">auto_start_machines</span> <span class=\"p\">=</span> <span class=\"kc\">true</span>\n  <span class=\"py\">min_machines_running</span> <span class=\"p\">=</span> <span class=\"mi\">0</span>\n  <span class=\"py\">processes</span> <span class=\"p\">=</span> <span class=\"nn\">[\"app\"]</span>\n\n<span class=\"nn\">[build]</span>\n  <span class=\"py\">image</span> <span class=\"p\">=</span> <span class=\"s\">\"ollama/ollama\"</span>\n\n<span class=\"nn\">[mounts]</span>\n  <span class=\"py\">source</span> <span class=\"p\">=</span> <span class=\"s\">\"models\"</span>\n  <span class=\"py\">destination</span> <span class=\"p\">=</span> <span class=\"s\">\"/root/.ollama\"</span>\n  <span class=\"py\">initial_size</span> <span class=\"p\">=</span> <span class=\"s\">\"100gb\"</span>\n</code></pre>\n  </div>\n</div>\n<p>Deploy this and bam, large language model inferencing from anywhere. If you want a private setup, see the article <a href=\"https://fly.io/blog/scaling-llm-ollama/\" title=\"\">Scaling Large Language Models to zero with Ollama</a> for more information. You never know when you have a sandwich emergency and don&rsquo;t know what you can make with what you have on hand.</p>\n\n<p>We are working on getting some lower-cost A10 GPUs in the next few weeks. We&rsquo;ll update you when they&rsquo;re ready.</p>\n\n<p>If you want to explore the possibilities of GPUs on Fly.io, here&rsquo;s a few articles that may give you ideas:</p>\n\n<ul>\n<li><a href=\"https://fly.io/blog/not-midjourney-bot/\" title=\"\">Deploy Your Own (Not) MidJourney Bot On Fly GPUs</a>\n</li><li><a href=\"https://fly.io/blog/scaling-llm-ollama/\" title=\"\">Scaling Large Language Models to zero with Ollama</a>\n</li><li><a href=\"https://fly.io/blog/transcribing-on-fly-gpu-machines/\" title=\"\">Transcribing on Fly GPU Machines</a>\n</li></ul>\n\n<p>Depending on factors such as your organization&rsquo;s age and payment history, you may need to go through additional verification steps.</p>\n\n<p>If you&rsquo;ve been experimenting with Fly.io GPUs and have made something cool, let us know on the <a href=\"https://community.fly.io/\" title=\"\">Community Forums</a> or by mentioning us <a href=\"https://hachyderm.io/@flydotio\" title=\"\">on Mastodon</a>! We&rsquo;ll boost the cool ones.</p>",
      "tier": "quick",
      "selection_reason": "GPU availability update for AI deployment",
      "audience_value": "Access to AI compute resources",
      "urgency_score": 7,
      "category_tag": "\u2601\ufe0f Enterprise Tech"
    },
    {
      "id": "173d3dae974732623015ba788b7f9ce7",
      "title": "The risks of cybersecurity tool sprawl: Why consolidation is a strategic priority",
      "url": "https://www.hashicorp.com/blog/the-risks-of-cybersecurity-tool-sprawl-and-why-we-need-consolidation",
      "published_date": "2026-02-23T08:54:45.053494",
      "description": "Cybersecurity tooling sprawl is killing organizations with risky complexity and high costs. This is the first in a two-part series exploring cybersecurity consolidation, why it matters, what it solves, and how to get started.",
      "source": "HashiCorp Blog",
      "category": "Cloud & Infrastructure",
      "segment": "builders",
      "source_type": "primary",
      "raw_content": "<p>New threats emerge every week, and many vendors respond with narrow, new reactive cybersecurity tool purchases to make sure a specific incident <em>never happens again</em>. The result? Tool sprawl. Some organizations now rely on anywhere from <a href=\"https://www.securus360.com/blog/so-many-cybersecurity-tools-deployed#:%7E:text=Businesses%20typically%20deploy%2045%20cybersecurity,ability%20to%20contain%20active%20attacks.\">45</a> to <a href=\"https://www.ibm.com/thought-leadership/institute-business-value/en-us/report/unified-cybersecurity-platform\">83</a> separate cybersecurity tools. </p>\n\n<p>This fragmented approach drives up costs, complicates workflows, and (believe it or not) actually increases risk and makes you less secure due to poor integration and limited visibility.</p>\n\n<p>Business leaders are taking notice:</p>\n\n<h2>What the data says on tool &amp; consolidation trends</h2>\n\n<ul>\n<li><a href=\"https://lsvp.com/cyber60-2024-2025/\">50% of CISOs</a> want to consolidate their security tools</li>\n<li><a href=\"https://blog.barracuda.com/2025/06/02/new-global-business-research-security-sprawl-increases-risk\">65% of orgs</a> say they have too many security tools, and over half (53%) say their tools can\u2019t be integrated.</li>\n<li><a href=\"https://www.gartner.com/en/newsroom/press-releases/2022-09-12-gartner-survey-shows-seventy-five-percent-of-organizations-are-pursuing-security-vendor-consolidation-in-2022\">75% of organizations</a> aim to reduce their number of security vendors</li>\n<li><a href=\"https://www.gartner.com/en/newsroom/press-releases/2022-09-12-gartner-survey-shows-seventy-five-percent-of-organizations-are-pursuing-security-vendor-consolidation-in-2022\">65% say consolidation</a> would improve their overall risk posture</li>\n</ul>\n\n<p>The message is clear: It\u2019s time to shift from being reactive to a more unified, strategic approach to cybersecurity.</p>\n\n<h2>What is cybersecurity tool sprawl?</h2>\n\n<p>Cybersecurity tool sprawl is a situation where you have an unnecessary number of cybersecurity tools when fewer tools could still cover all of the organization's needs for cybersecurity tool features. Fewer tools means easier management and lower costs.</p>\n\n<h2>What is cybersecurity vendor sprawl?</h2>\n\n<p>Same idea. Cybersecurity vendor sprawl is a situation where you have an unnecessary number of cybersecurity vendors when fewer vendors and tools could still cover all of the organization's needs for cybersecurity tool features. More tools from fewer vendors means easier relationship management with vendors and potentially lower costs due to bundling deals.</p>\n\n<h2>What are the negative impacts of tool &amp; vendor sprawl?</h2>\n\n<p>The negative effects of tool and vendor sprawl on costs, productivity, and risk profiles are well documented. But sometimes business leaders don\u2019t understand the full breadth of their potential downsides:</p>\n\n<ul>\n<li><p><strong>Overlapping functionality, unnecessary cost</strong></p>\n\n<p>Multiple tools that fulfill similar use cases are usually an unnecessary cost.</p></li>\n<li><p><strong>Detection is harder</strong> </p>\n\n<p>Vendor tools don\u2019t share data well, often resulting in missed opportunities to detect and correlate signals.</p></li>\n<li><p><strong>Too many tools, too many dashboards</strong></p>\n\n<p>Having to log into dozens of tools to analyze issues reduces productivity and increases the risk of missing vital alerts.</p></li>\n<li><p><strong>Higher integration workload</strong></p>\n\n<p>More tools mean more integration work \u2014 that is, assuming the tools support integration into a centralized dashboard.</p></li>\n<li><p><strong>Hard to debug and run audits (and run AI)</strong></p>\n\n<p>With more tools, it becomes harder to read and aggregate cybersecurity logs and other data into central locations for fast debugging and auditing, which means longer investigations and more lengthy, expensive audit cycles. </p></li>\n<li><p><strong>Shadow IT creates more attack surfaces</strong></p>\n\n<p>Sometimes tool sprawl is the result of shadow IT. This can sometimes open up more attack surfaces because those tools are not being used with company policies in mind. In a 2020 <a href=\"https://www.cisoplatform.com/profiles/blogs/gartner-predicts-30-of-breaches-due-to-shadow-it-by-2020\">report</a>, Gartner estimated that nearly one-third of all successful cyberattacks come from shadow IT infrastructure. With significant tool sprawl, you've created a virtual shadow IT regardless of whether it was done intentionally or not, because it's extremely hard to have enterprise security visibility over so many tools.</p></li>\n<li><p><strong>Alert fatigue</strong></p>\n\n<p>The more cybersecurity tools you have, the more alerts you\u2019ll likely get. Many tools are hard to fine-tune so that they don\u2019t produce a litany of false positives.</p></li>\n<li><p><strong>Too many vendors to potentially contact for support</strong></p>\n\n<p>Vendor sprawl means there are a multitude of vendors to track down and collaborate with when your inevitable support needs arise. </p></li>\n<li><p><strong>Worse sales deals</strong></p>\n\n<p>When you are buying lots of tools, budgeting and procurement becomes more complex and there are fewer opportunities for volume discounts.</p></li>\n<li><p><strong>Lost synergy gains</strong></p>\n\n<p>A DIY, custom-integrated cybersecurity toolchain requires more maintenance, and organizations miss out on many of the synergy gains that come from using a suite of tools that work together as a platform out of the box.</p></li>\n<li><p><strong>Slower incident response</strong></p>\n\n<p>As the number of cybersecurity tools, tests, and interfaces grows, it takes longer to update security policies, implement patches consistently across all environments, and complete threat analyses.</p></li>\n<li><p><strong>More maintenance costs</strong></p>\n\n<p>Aside from integration maintenance, more tools also mean more maintenance in general. </p></li>\n</ul>\n\n<h2>How to start your cybersecurity consolidation initiative</h2>\n\n<p>Tool sprawl is a growing problem, but it\u2019s also a solvable one. With the right strategy, organizations can reduce risk, streamline operations, and unlock real cost savings.</p>\n\n<p>Coming up in <a href=\"https://www.hashicorp.com/en/blog/how-to-start-consolidating-your-cybersecurity-tools\">part two of this blog</a>, we\u2019ll map out how to get started with cybersecurity toolchain rationalization and vendor consolidation, from aligning key teams to auditing your tooling landscape and identifying high-impact changes.  Stay tuned.</p>\n\n<h2>Real world case studies on consolidation</h2>\n\n<p>Organizational leaders must push their cybersecurity, engineering, and infrastructure operations teams to reduce complexity by centralizing and consolidating on a handful of security platforms rather than a litany of smaller cybersecurity tools.</p>\n\n<p>We\u2019ve seen <a href=\"https://www.hashicorp.com/en/resources/roche-s-transition-from-tools-to-platforms-with-terraform-and-vault\">Roche</a> and many other companies run successful cybersecurity product consolidation initiatives, and we\u2019d love to share more insights. We\u2019ve reduced risk for thousands of companies, including <a href=\"https://www.hashicorp.com/en/case-studies/vodafone-italy\">Vodafone</a>, <a href=\"https://www.hashicorp.com/en/case-studies/deutsche-bank\">Deutsche Bank</a>, <a href=\"https://www.hashicorp.com/en/case-studies/canva\">Canva</a>, and more.</p>\n\n<p>Download <a href=\"https://www.hashicorp.com/en/on-demand/secure-by-design?utm_source=hashicorp.com&amp;utm_medium=referral&amp;utm_campaign=26Q2_WW_BDM_RISK_the-risks-of-cybersecurity-tool-sprawl-why-we-need-consolidation&amp;utm_content=learn-more-conclusion&amp;utm_offer=whitepaper\">Secure by design: How to reduce cloud risk and maintain compliance</a> to learn how we can consolidate the number of Security Lifecycle Management tools you use.</p>\n\n<p><em>Blog last updated: January 12, 2026</em></p>",
      "tier": "quick",
      "selection_reason": "Critical security infrastructure insight",
      "audience_value": "Security strategy for AI systems",
      "urgency_score": 7,
      "category_tag": "\ud83d\udd10 Security"
    },
    {
      "id": "63344965c5aca90cbaf5c71a7eabbb21",
      "title": "Create new monetization opportunities with Stripe Billing\u2019s recent upgrades",
      "url": "https://stripe.com/blog/create-new-monetization-opportunities-with-recent-stripe-billing-upgrades",
      "published_date": "2026-02-23T08:54:38.979096",
      "description": "We recently released a series of improvements to expand multiprocessor support, give you more control over your billing and invoicing models, and better tailor your pricing for AI products. Here\u2019s everything that\u2019s new.",
      "source": "Stripe Blog",
      "category": "Engineering Blogs",
      "segment": "builders",
      "source_type": "primary",
      "raw_content": "We recently released a series of improvements to expand multiprocessor support, give you more control over your billing and invoicing models, and better tailor your pricing for AI products. Here\u2019s everything that\u2019s new.",
      "tier": "quick",
      "selection_reason": "New AI monetization capabilities",
      "audience_value": "AI business model implementation",
      "urgency_score": 7,
      "category_tag": "\ud83d\udcbc Tech Business"
    },
    {
      "id": "38c99d76100d06576104035868381784",
      "title": "Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams",
      "url": "https://sequoiacap.com/article/partnering-with-sandstone-an-ai-native-platform-for-in-house-legal-teams/",
      "published_date": "2026-02-23T08:54:32.401120",
      "description": "<p>The post <a href=\"https://sequoiacap.com/article/partnering-with-sandstone-an-ai-native-platform-for-in-house-legal-teams/\">Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams</a> appeared first on <a href=\"https://sequoiacap.com\">Sequoia Capital</a>.</p>",
      "source": "Sequoia Capital",
      "category": "Venture Capital & Funding",
      "segment": "leaders",
      "source_type": "primary",
      "raw_content": "<section class=\"wp-block-mg-hero-stack hero-stack\"><h1 class=\"hero-stack__title\">Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams</h1><div class=\"hero-stack__paragraph\"><p>Nick and Jarryd are empowering in-house legal teams to streamline and scale their operations.</p></div><div class=\"hero-stack__credits\"><div class=\"wp-block-mg-post-byline\">\n\tBy <a href=\"https://sequoiacap.com/people/bogomil-balkansky/\">Bogomil Balkansky</a>\t</div>\n\n\n<time class=\"wp-block-mg-post-date\" datetime=\"2026-01-13T06:30:08-08:00\">\nPublished January 13, 2026</time>\n</div></section>\n\n\n\n<figure class=\"wp-block-image size-large is-style-plain-caption\"><img alt=\"\" class=\"wp-image-21314\" height=\"683\" src=\"https://sequoiacap.com/wp-content/uploads/sites/6/2026/01/Sandstone-Founding-Team-Brooklyn-.png?w=1024\" width=\"1024\" /><figcaption class=\"wp-element-caption\">TEAM SANDSTONE.</figcaption></figure>\n\n\n\n<section class=\"wp-block-mg-post-container post-container wysiwyg has-global-padding is-layout-constrained wp-container-mg-post-container-is-layout-d839b035 wp-block-mg-post-container-is-layout-constrained\">\n<p class=\"has-drop-cap\">The first sentence of my Sequoia profile reads: \u201cHappenstance has been a theme in my life\u2014that, and being open to opportunities.\u201d</p>\n\n\n\n<p>Partnering with <a href=\"https://www.sandstone.com/\">Sandstone</a> is Exhibit A.</p>\n\n\n\n<p>I was introduced to CEO Nick Fleisher by Genevieve Forslund from our talent team. She had flagged Nick as an up-and-comer\u2014someone we should consider either for Sequoia itself or for one of our portfolio companies. She also introduced him to the CEO of a cybersecurity company we\u2019d partnered with.</p>\n\n\n\n<p>That CEO fell in love with Nick immediately and gave me explicit marching orders: \u201cYour mission is to help close Nick.\u201d</p>\n\n\n\n<p>I happened to be spending a month in New York. Over a few Negronis, I got to know him.</p>\n\n\n\n<p>What stood out right away was Nick\u2019s intensity\u2014the hunger to achieve. As a McKinsey alum, I was especially impressed that he made engagement manager at the firm in just 18 months by, in his words, \u201chacking the system.\u201d McKinsey is famously time-based, but Nick figured out that early specialization\u2014becoming a true domain expert\u2014was the fastest way to short-circuit the ladder. His trampoline was legal tech, which also turned out to be the preamble to his founder story.</p>\n\n\n\n<p>At the time, I was very much in pitch mode, trying to recruit him to our cybersecurity portfolio company. Nick\u2019s verdict: \u201cIf I were to take a job, this would be the one. But I really want to try my luck starting my own company.\u201d Fair enough, I thought. And of course, the next best thing to recruiting Nick into a portfolio company was partnering with him on his own entrepreneurial journey.</p>\n\n\n\n<p>My first question was simple: \u201cWhat will the company do?\u201d</p>\n\n\n\n<p>&#8220;Legal tech,&#8221; he replied. He told me he\u2019d spent his entire McKinsey career serving general counsels and overlooked mid-market in-house legal teams. Nick knew that AI could give these understaffed and overworked teams real leverage.</p>\n\n\n\n<p>That\u2019s where the serendipity kicked in.</p>\n\n\n\n<p>Back in 2019, before joining Sequoia, I had seriously considered starting a legal tech company myself. I had just left Google, and I was traveling the world, plotting my next move. The idea came from my time at VMware, where it had taken a team of 10 people to manually extract 62 key terms from licensing contracts. That stuck with me.</p>\n\n\n\n<p>I started calling GC friends in the Valley and quickly realized: <em>everyone</em> was doing some version of this. Spreadsheets as databases. Manual toil everywhere. The MVP became obvious\u2014use ML to extract key contract terms and populate a searchable system. This was pre-LLMs, but even then it felt doable.&nbsp;</p>\n\n\n\n<p>Had I started that company, it could easily have evolved into Sandstone: an AI-native workflow engine for in-house legal teams. Sandstone learns from a company\u2019s legal intelligence to execute work and simplify business operations, transforming their roles from reactive to strategic.</p>\n\n\n\n<p>At Sequoia, we often talk about the idea of a prepared mind\u2014doing the work on big market shifts before the opportunity shows up. In a sense, I\u2019d been preparing for Sandstone for years. Happily, so had Nick. When he told me his idea, I dusted off my 2019 Product Requirements Document and sent it to him. That may have sealed the deal. <img alt=\"\ud83d\ude42\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/17.0.2/72x72/1f642.png\" style=\"height: 1em;\" /></p>\n\n\n\n<p>Historically, legal tech hasn\u2019t been an easy market. But AI has fundamentally changed the dynamics. We\u2019re now seeing multiple legal AI companies scaling quickly, driven by two forces:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li>Law is the perfect LLM use case\u2014the profession is based on text in, text out.</li>\n\n\n\n<li>AI is most powerful when it automates expensive human toil, and few professions rely so heavily on highly trained people doing repetitive work.</li>\n</ol>\n\n\n\n<p>Before Sandstone, Sequoia had already partnered with Harvey (AI lawyer), Crosby (AI-enabled law firm), and Ironclad (AI contracting and contract lifecycle management), so we\u2019d seen these dynamics play out firsthand.</p>\n\n\n\n<p>Two months after meeting Nick, we led Sandstone\u2019s pre-seed. Along the way, we got to know his co-founder Jarryd Strydom\u2014another McKinsey alum, and a rare combination of attorney and builder.</p>\n\n\n\n<p>Nick and Jarryd accelerated from a standing start. They built the MVP in weeks, put it in front of customers immediately, and recruited an outstanding founding team that matches their intensity. The energy in their Brooklyn office is palpable, and it comes from the top. One of my favorite anecdotes: after a dinner together in NYC, we wrapped around 11pm\u2014and both Nick and Jarryd went straight back to the office.</p>\n\n\n\n<p>That speed and execution gave us the conviction to double down and lead Sandstone\u2019s seed round.</p>\n\n\n\n<p>And this is just the beginning. Sandstone is well on its way to transforming how legal teams operate and how business gets done.</p>\n</section>\n\n\n<section class=\"social-sharing\">\n\t<div class=\"social-sharing__container\">\n\t\t<h2 class=\"social-sharing__title caption caption--16\">Share</h2>\n\t\t<div class=\"social-sharing__options\">\n\t\t\t<button class=\"ico--facebook\">\n\t\t\t\t<span class=\"sr-only\">\n\t\t\t\tShare this on Facebook\t\t\t\t</span>\n\t\t\t</button>\n\t\t\t<button class=\"ico--twitter\">\n\t\t\t\t<span class=\"sr-only\">\n\t\t\t\tShare this on Twitter\t\t\t\t</span>\n\t\t\t</button>\n\t\t\t<button class=\"ico--linkedin\">\n\t\t\t\t<span class=\"sr-only\">\n\t\t\t\tShare this on LinkedIn\t\t\t\t</span>\n\t\t\t</button>\n\t\t\t<a class=\"ico--email\" href=\"mailto:?subject=Partnering+with+Sandstone:+An+AI-Native+Platform+for+In-House+Legal+Teams&#038;body=https%3A%2F%2Fsequoiacap.com%2Farticle%2Fpartnering-with-sandstone-an-ai-native-platform-for-in-house-legal-teams%2F\">\n\t\t\t\t<span class=\"sr-only\">Share this via email</span>\n\t\t\t</a>\n\t\t</div>\n\t</div>\n</section>\n\n\n<div class=\"tags grid\">\n\t<div class=\"grid__instances\">\n\t\t<div class=\"grid__instance\">\n\t\t\t<div class=\"tags__container grid__content\">\n\t\t\t\t<h2 class=\"tags__title caption caption--16\">Related Topics</h2>\n\t\t\t\t<div class=\"tags__links l-pillbox l-pillbox--centered\">\n\t\t\t\t\t<a class=\"tag\" href=\"https://sequoiacap.com/article/tag/ai/\" style=\"background-color: #fab23a;\">\n\t<span class=\"tag__name tag__name--dark\">#AI</span>\n</a>\n<a class=\"tag\" href=\"https://sequoiacap.com/article/tag/funding-announcement/\" style=\"background-color: #fab23a;\">\n\t<span class=\"tag__name tag__name--dark\">#Funding announcement</span>\n</a>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t</div>\n\t</div>\n</div>\n\n\n<div class=\"grid\">\n\t<div class=\"grid__instances\">\n\t<div class=\"grid__instance\"><div class=\"grid__content\"><a class=\"ink\" href=\"https://sequoiacap.com/article/partnering-with-traversal-because-every-engineer-remembers-their-first-time-troubleshooting/?itm_medium=related-content&#038;itm_source=sequoiacap.com\" style=\"background-color: #1b1916;\"><div class=\"ink__content\">\n\t<img alt=\"\" class=\"ink__image\" height=\"880\" src=\"https://sequoiacap.com/wp-content/uploads/sites/6/2025/06/Ink_Traversal.jpg?w=880&amp;h=880&amp;crop=1\" width=\"880\" />\t<div class=\"ink__text\">\n\t\t\n<h2 class=\"ink__title\">Partnering with Traversal</h2>\n\n\t<div class=\"ink__detail\">By Bogomil Balkansky and Charlie Curnin</div>\n\n<div class=\"ink__category ink__category--news\">News</div>\n\n<div class=\"ink__cta\">Read</div>\n\t</div>\n\t</div>\n</a></div></div><div class=\"grid__instance\"><div class=\"grid__content\"><a class=\"ink\" href=\"https://sequoiacap.com/article/partnering-with-fastapi-labs-simplified-app-deployment/?itm_medium=related-content&#038;itm_source=sequoiacap.com\" style=\"background-color: #1b1916;\"><div class=\"ink__content\">\n\t<img alt=\"\" class=\"ink__image\" height=\"880\" src=\"https://sequoiacap.com/wp-content/uploads/sites/6/2025/05/Fast-API-Labs_Ink.jpg?w=880&amp;h=880&amp;crop=1\" width=\"880\" />\t<div class=\"ink__text\">\n\t\t\n<h2 class=\"ink__title\">Partnering with FastAPI Labs: Simplified App Deployment </h2>\n\n\t<div class=\"ink__detail\">By Bogomil Balkansky and Lauren Reeder</div>\n\n<div class=\"ink__category ink__category--news\">News</div>\n\n<div class=\"ink__cta\">Read</div>\n\t</div>\n\t</div>\n</a></div></div><div class=\"grid__instance\"><div class=\"grid__content\"><a class=\"ink\" href=\"https://sequoiacap.com/article/partnering-with-apex-security-the-ai-empowered-future-secured/?itm_medium=related-content&#038;itm_source=sequoiacap.com\" style=\"background-color: #1b1916;\"><div class=\"ink__content\">\n\t<img alt=\"\" class=\"ink__image\" height=\"880\" src=\"https://sequoiacap.com/wp-content/uploads/sites/6/2024/04/Ink_Apex-Portrait.jpg?w=880&amp;h=880&amp;crop=1\" width=\"880\" />\t<div class=\"ink__text\">\n\t\t\n<h2 class=\"ink__title\">Partnering with Apex Security: The AI-Empowered Future, Secured</h2>\n\n\t<div class=\"ink__detail\">By Bogomil Balkansky</div>\n\n<div class=\"ink__category ink__category--news\">News</div>\n\n<div class=\"ink__cta\">Read</div>\n\t</div>\n\t</div>\n</a></div></div>\t</div>\n</div>\n\n\n<section class=\"wide-signup grid\">\n\t<div class=\"grid__instances\">\n\t\t<div class=\"grid__instance\">\n\t\t\t<div class=\"grid__content grid__content--dark\" style=\"background-color: transparent;\">\n\t\t\t\t<div class=\"wide-signup__container\">\n\n\t\t\t\t\t<div class=\"wide-signup__intro\">\n\t\t\t\t\t\tJOIN OUR MAILING LIST\t\t\t\t\t</div>\n\n\t\t\t\t\t<h1 class=\"wide-signup__title\">\n\t\t\t\t\t\tGet the best stories from the Sequoia community.\t\t\t\t\t</h1>\n\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t<div class=\"wide-signup__form\">\n\t\t\t\t\t\t\n<!-- Mailchimp for WordPress v4.10.9 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-9292\" id=\"mc4wp-form-6\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"mailchimp__wrapper\">\n\t<label class=\"mailchimp__label-input\">\n\t\t<span class=\"sr-only\">Email address</span>\n\t\t<input name=\"EMAIL\" required=\"required\" type=\"email\" />\n\t</label>\n\n\t<input class=\"button--filled button--medium button--outline-dark\" type=\"submit\" value=\"Submit\" />\n</div></div><label style=\"display: none !important;\">Leave this field empty if you&#8217;re human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\" /></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1771836526\" /><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"9292\" /><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-6\" /><div class=\"mc4wp-response\"></div></form><!-- / Mailchimp for WordPress Plugin -->\n\n\t\t\t\t\t</div>\n\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t</div>\n\t</div>\n</section>\n<p>The post <a href=\"https://sequoiacap.com/article/partnering-with-sandstone-an-ai-native-platform-for-in-house-legal-teams/\">Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams</a> appeared first on <a href=\"https://sequoiacap.com\">Sequoia Capital</a>.</p>",
      "tier": "quick",
      "selection_reason": "AI innovation in legal tech",
      "audience_value": "Vertical-specific AI application",
      "urgency_score": 7,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "f4ce340c96e4e50ad9b31a907fecb651",
      "title": "An AI coding bot took down Amazon Web Services",
      "url": "https://arstechnica.com/ai/2026/02/an-ai-coding-bot-took-down-amazon-web-services/",
      "published_date": "2026-02-23T08:54:54.573589",
      "description": "Blames \"user error, not AI error\" for incident in December involving its Kiro tool.",
      "source": "Ars Technica - All content",
      "category": "Tech Innovation",
      "segment": "innovators",
      "source_type": "secondary",
      "raw_content": "<p>Amazon\u2019s cloud unit has suffered at least two outages due to errors involving its own AI tools, leading some employees to raise doubts about the US tech giant\u2019s push to roll out these coding assistants.</p>\n<p>Amazon Web Services experienced a 13-hour interruption to one system used by its customers in mid-December after engineers allowed its Kiro AI coding tool to make certain changes, according to four people familiar with the matter.</p>\n<p>The people said the agentic tool, which can take autonomous actions on behalf of users, determined that the best course of action was to \u201cdelete and recreate the environment.\u201d</p><p><a href=\"https://arstechnica.com/ai/2026/02/an-ai-coding-bot-took-down-amazon-web-services/\">Read full article</a></p>\n<p><a href=\"https://arstechnica.com/ai/2026/02/an-ai-coding-bot-took-down-amazon-web-services/#comments\">Comments</a></p>",
      "tier": "trending",
      "selection_reason": "High-impact AI incident analysis",
      "audience_value": "Learning from AI deployment failures",
      "urgency_score": 8,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "901a6f84fefa2a684f6d99fb2c65c88f",
      "title": "OpenAI says 18- to 24-year-olds account for nearly 50% of ChatGPT usage in India",
      "url": "https://techcrunch.com/2026/02/20/openai-says-18-to-24-year-olds-account-for-nearly-50-of-chatgpt-usage-in-india/",
      "published_date": "2026-02-23T08:54:55.404302",
      "description": "The company said on Friday that users between 18 and 24 years of age account for nearly 50% of all messages sent by Indians to ChatGPT, and users under 30 account for 80% of usage in the country.",
      "source": "AI News & Artificial Intelligence | TechCrunch",
      "category": "Emerging Tech",
      "segment": "innovators",
      "source_type": "secondary",
      "raw_content": "The company said on Friday that users between 18 and 24 years of age account for nearly 50% of all messages sent by Indians to ChatGPT, and users under 30 account for 80% of usage in the country.",
      "tier": "trending",
      "selection_reason": "AI adoption demographic insights",
      "audience_value": "Understanding AI market dynamics",
      "urgency_score": 7,
      "category_tag": "\ud83d\udcca Market Trends"
    }
  ]
}