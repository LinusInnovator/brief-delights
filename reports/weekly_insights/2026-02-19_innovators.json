{
  "date": "2026-02-19",
  "segment": "innovators",
  "trends": {
    "categories": {
      "AI Research & Labs": 2,
      "ML Community & Tools": 2,
      "AI & Machine Learning": 2,
      "Academic Research": 1,
      "Venture Capital & Funding": 1,
      "Developer Tools & Platforms": 1,
      "Management & Leadership": 1,
      "Database & Backend": 1,
      "AI & Innovation": 1,
      "Developer & Engineering": 1
    },
    "sources": {
      "Google Blog": 2,
      "Hugging Face - Blog": 2,
      "MachineLearningMastery.com": 2,
      "Computer science : nature.com subject feeds": 1,
      "Sequoia Capital": 1,
      "The Fly Blog": 1,
      "MIT Sloan Management Review": 1,
      "Blog \u2014 PlanetScale": 1,
      "WIRED": 1,
      "Coding Horror": 1
    },
    "topics": [
      "Open-source AI tool beats giant LLMs in literature reviews \u2014 and gets citations right",
      "How animators and AI researchers made \u2018Dear Upstairs Neighbors\u2019",
      "Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams",
      "GPUs on Fly.io are available to everyone!",
      "Connecting Language and (Artificial) Intelligence: Princeton\u2019s Tom Griffiths",
      "Videos: Intro to Vitess\u2014its powerful capabilities and how to get started",
      "Robot Dogs Are on Going on Patrol at the 2026 World Cup in Mexico",
      "In our latest podcast, hear how the \u201cSmoke Jumpers\u201d team brings Gemini to billions of people.",
      "How to train a new language model from scratch using Transformers and Tokenizers",
      "How to generate text: using different decoding methods for language generation with Transformers",
      "7 Advanced Feature Engineering Tricks Using LLM Embeddings",
      "Export Your ML Model in ONNX Format",
      "There is no longer any such thing as Computer Security",
      "WordPress.com adds an AI Assistant that can edit, adjust styles, create images, and more"
    ],
    "total_articles": 14
  },
  "article_count": 14,
  "articles": [
    {
      "id": "ff7e0fead3f35a5821a0c472ef592720",
      "title": "Open-source AI tool beats giant LLMs in literature reviews \u2014 and gets citations right",
      "url": "https://www.nature.com/articles/d41586-026-00347-9",
      "published_date": "2026-02-19T06:59:29.689451",
      "description": "",
      "source": "Computer science : nature.com subject feeds",
      "category": "Academic Research",
      "segment": "innovators",
      "source_type": "primary",
      "raw_content": "",
      "tier": "full",
      "selection_reason": "Breakthrough in AI literature review capabilities challenges larger models",
      "audience_value": "Insights into emerging AI tools that outperform established players",
      "urgency_score": 9,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "178c06f679769e19059a723f2be344ac",
      "title": "How animators and AI researchers made \u2018Dear Upstairs Neighbors\u2019",
      "url": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/dear-upstairs-neighbors/",
      "published_date": "2026-02-19T06:59:28.512053",
      "description": "A movie poster for a film titled \u201cDear Upstairs Neighbors\u201d, hand-painted in a vivid expressionist style, featuring an exasperated cartoon woman clutching her ears, surrounded by neon-colored images of noisy things like howling dogs and stomping shoes",
      "source": "Google Blog",
      "category": "AI Research & Labs",
      "segment": "innovators",
      "source_type": "primary",
      "raw_content": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/DUN_poster_16x9_v02.max-600x600.format-webp.webp\">Today, our animated short film, \u201cDear Upstairs Neighbors,\u201d previews at the Sundance Film Festival.",
      "tier": "full",
      "selection_reason": "Novel intersection of AI research and creative animation",
      "audience_value": "Real-world application of cutting-edge AI in creative industries",
      "urgency_score": 8,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "38c99d76100d06576104035868381784",
      "title": "Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams",
      "url": "https://sequoiacap.com/article/partnering-with-sandstone-an-ai-native-platform-for-in-house-legal-teams/",
      "published_date": "2026-02-19T06:59:18.738732",
      "description": "<p>The post <a href=\"https://sequoiacap.com/article/partnering-with-sandstone-an-ai-native-platform-for-in-house-legal-teams/\">Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams</a> appeared first on <a href=\"https://sequoiacap.com\">Sequoia Capital</a>.</p>",
      "source": "Sequoia Capital",
      "category": "Venture Capital & Funding",
      "segment": "leaders",
      "source_type": "primary",
      "raw_content": "<section class=\"wp-block-mg-hero-stack hero-stack\"><h1 class=\"hero-stack__title\">Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams</h1><div class=\"hero-stack__paragraph\"><p>Nick and Jarryd are empowering in-house legal teams to streamline and scale their operations.</p></div><div class=\"hero-stack__credits\"><div class=\"wp-block-mg-post-byline\">\n\tBy <a href=\"https://sequoiacap.com/people/bogomil-balkansky/\">Bogomil Balkansky</a>\t</div>\n\n\n<time class=\"wp-block-mg-post-date\" datetime=\"2026-01-13T06:30:08-08:00\">\nPublished January 13, 2026</time>\n</div></section>\n\n\n\n<figure class=\"wp-block-image size-large is-style-plain-caption\"><img alt=\"\" class=\"wp-image-21314\" height=\"683\" src=\"https://sequoiacap.com/wp-content/uploads/sites/6/2026/01/Sandstone-Founding-Team-Brooklyn-.png?w=1024\" width=\"1024\" /><figcaption class=\"wp-element-caption\">TEAM SANDSTONE.</figcaption></figure>\n\n\n\n<section class=\"wp-block-mg-post-container post-container wysiwyg has-global-padding is-layout-constrained wp-container-mg-post-container-is-layout-d839b035 wp-block-mg-post-container-is-layout-constrained\">\n<p class=\"has-drop-cap\">The first sentence of my Sequoia profile reads: \u201cHappenstance has been a theme in my life\u2014that, and being open to opportunities.\u201d</p>\n\n\n\n<p>Partnering with <a href=\"https://www.sandstone.com/\">Sandstone</a> is Exhibit A.</p>\n\n\n\n<p>I was introduced to CEO Nick Fleisher by Genevieve Forslund from our talent team. She had flagged Nick as an up-and-comer\u2014someone we should consider either for Sequoia itself or for one of our portfolio companies. She also introduced him to the CEO of a cybersecurity company we\u2019d partnered with.</p>\n\n\n\n<p>That CEO fell in love with Nick immediately and gave me explicit marching orders: \u201cYour mission is to help close Nick.\u201d</p>\n\n\n\n<p>I happened to be spending a month in New York. Over a few Negronis, I got to know him.</p>\n\n\n\n<p>What stood out right away was Nick\u2019s intensity\u2014the hunger to achieve. As a McKinsey alum, I was especially impressed that he made engagement manager at the firm in just 18 months by, in his words, \u201chacking the system.\u201d McKinsey is famously time-based, but Nick figured out that early specialization\u2014becoming a true domain expert\u2014was the fastest way to short-circuit the ladder. His trampoline was legal tech, which also turned out to be the preamble to his founder story.</p>\n\n\n\n<p>At the time, I was very much in pitch mode, trying to recruit him to our cybersecurity portfolio company. Nick\u2019s verdict: \u201cIf I were to take a job, this would be the one. But I really want to try my luck starting my own company.\u201d Fair enough, I thought. And of course, the next best thing to recruiting Nick into a portfolio company was partnering with him on his own entrepreneurial journey.</p>\n\n\n\n<p>My first question was simple: \u201cWhat will the company do?\u201d</p>\n\n\n\n<p>&#8220;Legal tech,&#8221; he replied. He told me he\u2019d spent his entire McKinsey career serving general counsels and overlooked mid-market in-house legal teams. Nick knew that AI could give these understaffed and overworked teams real leverage.</p>\n\n\n\n<p>That\u2019s where the serendipity kicked in.</p>\n\n\n\n<p>Back in 2019, before joining Sequoia, I had seriously considered starting a legal tech company myself. I had just left Google, and I was traveling the world, plotting my next move. The idea came from my time at VMware, where it had taken a team of 10 people to manually extract 62 key terms from licensing contracts. That stuck with me.</p>\n\n\n\n<p>I started calling GC friends in the Valley and quickly realized: <em>everyone</em> was doing some version of this. Spreadsheets as databases. Manual toil everywhere. The MVP became obvious\u2014use ML to extract key contract terms and populate a searchable system. This was pre-LLMs, but even then it felt doable.&nbsp;</p>\n\n\n\n<p>Had I started that company, it could easily have evolved into Sandstone: an AI-native workflow engine for in-house legal teams. Sandstone learns from a company\u2019s legal intelligence to execute work and simplify business operations, transforming their roles from reactive to strategic.</p>\n\n\n\n<p>At Sequoia, we often talk about the idea of a prepared mind\u2014doing the work on big market shifts before the opportunity shows up. In a sense, I\u2019d been preparing for Sandstone for years. Happily, so had Nick. When he told me his idea, I dusted off my 2019 Product Requirements Document and sent it to him. That may have sealed the deal. <img alt=\"\ud83d\ude42\" class=\"wp-smiley\" src=\"https://s.w.org/images/core/emoji/17.0.2/72x72/1f642.png\" style=\"height: 1em;\" /></p>\n\n\n\n<p>Historically, legal tech hasn\u2019t been an easy market. But AI has fundamentally changed the dynamics. We\u2019re now seeing multiple legal AI companies scaling quickly, driven by two forces:</p>\n\n\n\n<ol class=\"wp-block-list\">\n<li>Law is the perfect LLM use case\u2014the profession is based on text in, text out.</li>\n\n\n\n<li>AI is most powerful when it automates expensive human toil, and few professions rely so heavily on highly trained people doing repetitive work.</li>\n</ol>\n\n\n\n<p>Before Sandstone, Sequoia had already partnered with Harvey (AI lawyer), Crosby (AI-enabled law firm), and Ironclad (AI contracting and contract lifecycle management), so we\u2019d seen these dynamics play out firsthand.</p>\n\n\n\n<p>Two months after meeting Nick, we led Sandstone\u2019s pre-seed. Along the way, we got to know his co-founder Jarryd Strydom\u2014another McKinsey alum, and a rare combination of attorney and builder.</p>\n\n\n\n<p>Nick and Jarryd accelerated from a standing start. They built the MVP in weeks, put it in front of customers immediately, and recruited an outstanding founding team that matches their intensity. The energy in their Brooklyn office is palpable, and it comes from the top. One of my favorite anecdotes: after a dinner together in NYC, we wrapped around 11pm\u2014and both Nick and Jarryd went straight back to the office.</p>\n\n\n\n<p>That speed and execution gave us the conviction to double down and lead Sandstone\u2019s seed round.</p>\n\n\n\n<p>And this is just the beginning. Sandstone is well on its way to transforming how legal teams operate and how business gets done.</p>\n</section>\n\n\n<section class=\"social-sharing\">\n\t<div class=\"social-sharing__container\">\n\t\t<h2 class=\"social-sharing__title caption caption--16\">Share</h2>\n\t\t<div class=\"social-sharing__options\">\n\t\t\t<button class=\"ico--facebook\">\n\t\t\t\t<span class=\"sr-only\">\n\t\t\t\tShare this on Facebook\t\t\t\t</span>\n\t\t\t</button>\n\t\t\t<button class=\"ico--twitter\">\n\t\t\t\t<span class=\"sr-only\">\n\t\t\t\tShare this on Twitter\t\t\t\t</span>\n\t\t\t</button>\n\t\t\t<button class=\"ico--linkedin\">\n\t\t\t\t<span class=\"sr-only\">\n\t\t\t\tShare this on LinkedIn\t\t\t\t</span>\n\t\t\t</button>\n\t\t\t<a class=\"ico--email\" href=\"mailto:?subject=Partnering+with+Sandstone:+An+AI-Native+Platform+for+In-House+Legal+Teams&#038;body=https%3A%2F%2Fsequoiacap.com%2Farticle%2Fpartnering-with-sandstone-an-ai-native-platform-for-in-house-legal-teams%2F\">\n\t\t\t\t<span class=\"sr-only\">Share this via email</span>\n\t\t\t</a>\n\t\t</div>\n\t</div>\n</section>\n\n\n<div class=\"tags grid\">\n\t<div class=\"grid__instances\">\n\t\t<div class=\"grid__instance\">\n\t\t\t<div class=\"tags__container grid__content\">\n\t\t\t\t<h2 class=\"tags__title caption caption--16\">Related Topics</h2>\n\t\t\t\t<div class=\"tags__links l-pillbox l-pillbox--centered\">\n\t\t\t\t\t<a class=\"tag\" href=\"https://sequoiacap.com/article/tag/ai/\" style=\"background-color: #fab23a;\">\n\t<span class=\"tag__name tag__name--dark\">#AI</span>\n</a>\n<a class=\"tag\" href=\"https://sequoiacap.com/article/tag/funding-announcement/\" style=\"background-color: #fab23a;\">\n\t<span class=\"tag__name tag__name--dark\">#Funding announcement</span>\n</a>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t</div>\n\t</div>\n</div>\n\n\n<div class=\"grid\">\n\t<div class=\"grid__instances\">\n\t<div class=\"grid__instance\"><div class=\"grid__content\"><a class=\"ink\" href=\"https://sequoiacap.com/article/partnering-with-traversal-because-every-engineer-remembers-their-first-time-troubleshooting/?itm_medium=related-content&#038;itm_source=sequoiacap.com\" style=\"background-color: #1b1916;\"><div class=\"ink__content\">\n\t<img alt=\"\" class=\"ink__image\" height=\"880\" src=\"https://sequoiacap.com/wp-content/uploads/sites/6/2025/06/Ink_Traversal.jpg?w=880&amp;h=880&amp;crop=1\" width=\"880\" />\t<div class=\"ink__text\">\n\t\t\n<h2 class=\"ink__title\">Partnering with Traversal</h2>\n\n\t<div class=\"ink__detail\">By Bogomil Balkansky and Charlie Curnin</div>\n\n<div class=\"ink__category ink__category--news\">News</div>\n\n<div class=\"ink__cta\">Read</div>\n\t</div>\n\t</div>\n</a></div></div><div class=\"grid__instance\"><div class=\"grid__content\"><a class=\"ink\" href=\"https://sequoiacap.com/article/partnering-with-fastapi-labs-simplified-app-deployment/?itm_medium=related-content&#038;itm_source=sequoiacap.com\" style=\"background-color: #1b1916;\"><div class=\"ink__content\">\n\t<img alt=\"\" class=\"ink__image\" height=\"880\" src=\"https://sequoiacap.com/wp-content/uploads/sites/6/2025/05/Fast-API-Labs_Ink.jpg?w=880&amp;h=880&amp;crop=1\" width=\"880\" />\t<div class=\"ink__text\">\n\t\t\n<h2 class=\"ink__title\">Partnering with FastAPI Labs: Simplified App Deployment </h2>\n\n\t<div class=\"ink__detail\">By Bogomil Balkansky and Lauren Reeder</div>\n\n<div class=\"ink__category ink__category--news\">News</div>\n\n<div class=\"ink__cta\">Read</div>\n\t</div>\n\t</div>\n</a></div></div><div class=\"grid__instance\"><div class=\"grid__content\"><a class=\"ink\" href=\"https://sequoiacap.com/article/partnering-with-apex-security-the-ai-empowered-future-secured/?itm_medium=related-content&#038;itm_source=sequoiacap.com\" style=\"background-color: #1b1916;\"><div class=\"ink__content\">\n\t<img alt=\"\" class=\"ink__image\" height=\"880\" src=\"https://sequoiacap.com/wp-content/uploads/sites/6/2024/04/Ink_Apex-Portrait.jpg?w=880&amp;h=880&amp;crop=1\" width=\"880\" />\t<div class=\"ink__text\">\n\t\t\n<h2 class=\"ink__title\">Partnering with Apex Security: The AI-Empowered Future, Secured</h2>\n\n\t<div class=\"ink__detail\">By Bogomil Balkansky</div>\n\n<div class=\"ink__category ink__category--news\">News</div>\n\n<div class=\"ink__cta\">Read</div>\n\t</div>\n\t</div>\n</a></div></div>\t</div>\n</div>\n\n\n<section class=\"wide-signup grid\">\n\t<div class=\"grid__instances\">\n\t\t<div class=\"grid__instance\">\n\t\t\t<div class=\"grid__content grid__content--dark\" style=\"background-color: transparent;\">\n\t\t\t\t<div class=\"wide-signup__container\">\n\n\t\t\t\t\t<div class=\"wide-signup__intro\">\n\t\t\t\t\t\tJOIN OUR MAILING LIST\t\t\t\t\t</div>\n\n\t\t\t\t\t<h1 class=\"wide-signup__title\">\n\t\t\t\t\t\tGet the best stories from the Sequoia community.\t\t\t\t\t</h1>\n\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t<div class=\"wide-signup__form\">\n\t\t\t\t\t\t\n<!-- Mailchimp for WordPress v4.10.9 - https://wordpress.org/plugins/mailchimp-for-wp/ --><form class=\"mc4wp-form mc4wp-form-9292\" id=\"mc4wp-form-6\" method=\"post\"><div class=\"mc4wp-form-fields\"><div class=\"mailchimp__wrapper\">\n\t<label class=\"mailchimp__label-input\">\n\t\t<span class=\"sr-only\">Email address</span>\n\t\t<input name=\"EMAIL\" required=\"required\" type=\"email\" />\n\t</label>\n\n\t<input class=\"button--filled button--medium button--outline-dark\" type=\"submit\" value=\"Submit\" />\n</div></div><label style=\"display: none !important;\">Leave this field empty if you&#8217;re human: <input autocomplete=\"off\" name=\"_mc4wp_honeypot\" tabindex=\"-1\" type=\"text\" value=\"\" /></label><input name=\"_mc4wp_timestamp\" type=\"hidden\" value=\"1771482093\" /><input name=\"_mc4wp_form_id\" type=\"hidden\" value=\"9292\" /><input name=\"_mc4wp_form_element_id\" type=\"hidden\" value=\"mc4wp-form-6\" /><div class=\"mc4wp-response\"></div></form><!-- / Mailchimp for WordPress Plugin -->\n\n\t\t\t\t\t</div>\n\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t</div>\n\t</div>\n</section>\n<p>The post <a href=\"https://sequoiacap.com/article/partnering-with-sandstone-an-ai-native-platform-for-in-house-legal-teams/\">Partnering with Sandstone: An AI-Native Platform for In-House Legal Teams</a> appeared first on <a href=\"https://sequoiacap.com\">Sequoia Capital</a>.</p>",
      "tier": "full",
      "selection_reason": "Emerging AI platform revolutionizing legal tech",
      "audience_value": "Early insight into AI transformation of traditional industries",
      "urgency_score": 9,
      "category_tag": "\ud83d\udcbc Tech Business"
    },
    {
      "id": "49203b8704dd69f2cdc72cfa067ffb5b",
      "title": "GPUs on Fly.io are available to everyone!",
      "url": "https://fly.io/blog/gpu-ga/",
      "published_date": "2026-02-19T06:59:38.552409",
      "description": "<div class=\"lead\"><p>Fly.io makes it easy to spin up compute around the world, now including powerful GPUs. Unlock the power of large language models, text transcription, and image generation with our datacenter-grade muscle!</p>\n</div>\n<p>GPUs are now available to everyone!</p>\n\n<p>We know you&rsquo;ve been excited about wanting to use GPUs on Fly.io and we&rsquo;re happy to announce that they&rsquo;re available for everyone. If you want, you can spin up GPU instances with any of the following cards:</p>\n\n<ul>\n<li>Ampere A100 (40GB) <code>a100-40gb</code>\n</li><li>Ampere A100 (80GB) <code>a100-80gb</code>\n</li><li>Lovelace L40s (48GB) <code>l40s</code>\n</li></ul>\n\n<p>To use a GPU instance today, change the <code>vm.size</code> for one of your apps or processes to any of the above GPU kinds. Here&rsquo;s how you can spin up an <a href=\"https://ollama.ai\" title=\"\">Ollama</a> server in seconds:</p>\n<div class=\"highlight-wrapper group relative toml\">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-rumbg9gv\"><span class=\"py\">app</span> <span class=\"p\">=</span> <span class=\"s\">\"your-app-name\"</span>\n<span class=\"py\">region</span> <span class=\"p\">=</span> <span class=\"s\">\"ord\"</span>\n<span class=\"py\">vm.size</span> <span class=\"p\">=</span> <span class=\"s\">\"l40s\"</span>\n\n<span class=\"nn\">[http_service]</span>\n  <span class=\"py\">internal_port</span> <span class=\"p\">=</span> <span class=\"mi\">11434</span>\n  <span class=\"py\">force_https</span> <span class=\"p\">=</span> <span class=\"kc\">false</span>\n  <span class=\"py\">auto_stop_machines</span> <span class=\"p\">=</span> <span class=\"kc\">true</span>\n  <span class=\"py\">auto_start_machines</span> <span class=\"p\">=</span> <span class=\"kc\">true</span>\n  <span class=\"py\">min_machines_running</span> <span class=\"p\">=</span> <span class=\"mi\">0</span>\n  <span class=\"py\">processes</span> <span class=\"p\">=</span> <span class=\"nn\">[\"app\"]</span>\n\n<span class=\"nn\">[build]</span>\n  <span class=\"py\">image</span> <span class=\"p\">=</span> <span class=\"s\">\"ollama/ollama\"</span>\n\n<span class=\"nn\">[mounts]</span>\n  <span class=\"py\">source</span> <span class=\"p\">=</span> <span class=\"s\">\"models\"</span>\n  <span class=\"py\">destination</span> <span class=\"p\">=</span> <span class=\"s\">\"/root/.ollama\"</span>\n  <span class=\"py\">initial_size</span> <span class=\"p\">=</span> <span class=\"s\">\"100gb\"</span>\n</code></pre>\n  </div>\n</div>\n<p>Deploy this and bam, large language model inferencing from anywhere. If you want a private setup, see the article <a href=\"https://fly.io/blog/scaling-llm-ollama/\" title=\"\">Scaling Large Language Models to zero with Ollama</a> for more information. You never know when you have a sandwich emergency and don&rsquo;t know what you can make with what you have on hand.</p>\n\n<p>We are working on getting some lower-cost A10 GPUs in the next few weeks. We&rsquo;ll update you when they&rsquo;re ready.</p>\n\n<p>If you want to explore the possibilities of GPUs on Fly.io, here&rsquo;s a few articles that may give you ideas:</p>\n\n<ul>\n<li><a href=\"https://fly.io/blog/not-midjourney-bot/\" title=\"\">Deploy Your Own (Not) MidJourney Bot On Fly GPUs</a>\n</li><li><a href=\"https://fly.io/blog/scaling-llm-ollama/\" title=\"\">Scaling Large Language Models to zero with Ollama</a>\n</li><li><a href=\"https://fly.io/blog/transcribing-on-fly-gpu-machines/\" title=\"\">Transcribing on Fly GPU Machines</a>\n</li></ul>\n\n<p>Depending on factors such as your organization&rsquo;s age and payment history, you may need to go through additional verification steps.</p>\n\n<p>If you&rsquo;ve been experimenting with Fly.io GPUs and have made something cool, let us know on the <a href=\"https://community.fly.io/\" title=\"\">Community Forums</a> or by mentioning us <a href=\"https://hachyderm.io/@flydotio\" title=\"\">on Mastodon</a>! We&rsquo;ll boost the cool ones.</p>",
      "source": "The Fly Blog",
      "category": "Developer Tools & Platforms",
      "segment": "builders",
      "source_type": "primary",
      "raw_content": "<div class=\"lead\"><p>Fly.io makes it easy to spin up compute around the world, now including powerful GPUs. Unlock the power of large language models, text transcription, and image generation with our datacenter-grade muscle!</p>\n</div>\n<p>GPUs are now available to everyone!</p>\n\n<p>We know you&rsquo;ve been excited about wanting to use GPUs on Fly.io and we&rsquo;re happy to announce that they&rsquo;re available for everyone. If you want, you can spin up GPU instances with any of the following cards:</p>\n\n<ul>\n<li>Ampere A100 (40GB) <code>a100-40gb</code>\n</li><li>Ampere A100 (80GB) <code>a100-80gb</code>\n</li><li>Lovelace L40s (48GB) <code>l40s</code>\n</li></ul>\n\n<p>To use a GPU instance today, change the <code>vm.size</code> for one of your apps or processes to any of the above GPU kinds. Here&rsquo;s how you can spin up an <a href=\"https://ollama.ai\" title=\"\">Ollama</a> server in seconds:</p>\n<div class=\"highlight-wrapper group relative toml\">\n  <button class=\"bubble-wrap z-20 absolute right-9 -mr-0.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M9.912 8.037h2.732c1.277 0 2.315-.962 2.315-2.237a2.325 2.325 0 00-2.315-2.31H2.959m10.228 9.01H2.959M6.802 8H2.959\"><path d=\"M11.081 6.466L9.533 8.037l1.548 1.571\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-9px] tail text-navy-950\">\n      Wrap text\n    </span>\n  </button>\n  <button class=\"bubble-wrap z-20 absolute right-1.5 top-1.5 text-transparent group-hover:text-gray-400 group-hover:hocus:text-white focus:text-white bg-transparent group-hover:bg-gray-900 group-hover:hocus:bg-gray-700 focus:bg-gray-700 transition-colors grid place-items-center w-7 h-7 rounded-lg outline-none focus:outline-none\" type=\"button\">\n    <svg class=\"w-4 h-4 pointer-events-none\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"1.35\" viewBox=\"0 0 16 16\" xmlns=\"http://www.w3.org/2000/svg\"><g><path d=\"M10.576 7.239c0-.995-.82-1.815-1.815-1.815H3.315c-.995 0-1.815.82-1.815 1.815v5.446c0 .995.82 1.815 1.815 1.815h5.446c.995 0 1.815-.82 1.815-1.815V7.239z\"><path d=\"M10.576 10.577h2.109A1.825 1.825 0 0014.5 8.761V3.315A1.826 1.826 0 0012.685 1.5H7.239c-.996 0-1.815.819-1.816 1.815v1.617\"></g></svg>\n    <span class=\"bubble-sm bubble-tl [--offset-l:-6px] tail [--tail-x:calc(100%-30px)] text-navy-950\">\n      Copy to clipboard\n    </span>\n  </button>\n  <div class=\"highlight relative group\">\n    <pre class=\"highlight \"><code id=\"code-rumbg9gv\"><span class=\"py\">app</span> <span class=\"p\">=</span> <span class=\"s\">\"your-app-name\"</span>\n<span class=\"py\">region</span> <span class=\"p\">=</span> <span class=\"s\">\"ord\"</span>\n<span class=\"py\">vm.size</span> <span class=\"p\">=</span> <span class=\"s\">\"l40s\"</span>\n\n<span class=\"nn\">[http_service]</span>\n  <span class=\"py\">internal_port</span> <span class=\"p\">=</span> <span class=\"mi\">11434</span>\n  <span class=\"py\">force_https</span> <span class=\"p\">=</span> <span class=\"kc\">false</span>\n  <span class=\"py\">auto_stop_machines</span> <span class=\"p\">=</span> <span class=\"kc\">true</span>\n  <span class=\"py\">auto_start_machines</span> <span class=\"p\">=</span> <span class=\"kc\">true</span>\n  <span class=\"py\">min_machines_running</span> <span class=\"p\">=</span> <span class=\"mi\">0</span>\n  <span class=\"py\">processes</span> <span class=\"p\">=</span> <span class=\"nn\">[\"app\"]</span>\n\n<span class=\"nn\">[build]</span>\n  <span class=\"py\">image</span> <span class=\"p\">=</span> <span class=\"s\">\"ollama/ollama\"</span>\n\n<span class=\"nn\">[mounts]</span>\n  <span class=\"py\">source</span> <span class=\"p\">=</span> <span class=\"s\">\"models\"</span>\n  <span class=\"py\">destination</span> <span class=\"p\">=</span> <span class=\"s\">\"/root/.ollama\"</span>\n  <span class=\"py\">initial_size</span> <span class=\"p\">=</span> <span class=\"s\">\"100gb\"</span>\n</code></pre>\n  </div>\n</div>\n<p>Deploy this and bam, large language model inferencing from anywhere. If you want a private setup, see the article <a href=\"https://fly.io/blog/scaling-llm-ollama/\" title=\"\">Scaling Large Language Models to zero with Ollama</a> for more information. You never know when you have a sandwich emergency and don&rsquo;t know what you can make with what you have on hand.</p>\n\n<p>We are working on getting some lower-cost A10 GPUs in the next few weeks. We&rsquo;ll update you when they&rsquo;re ready.</p>\n\n<p>If you want to explore the possibilities of GPUs on Fly.io, here&rsquo;s a few articles that may give you ideas:</p>\n\n<ul>\n<li><a href=\"https://fly.io/blog/not-midjourney-bot/\" title=\"\">Deploy Your Own (Not) MidJourney Bot On Fly GPUs</a>\n</li><li><a href=\"https://fly.io/blog/scaling-llm-ollama/\" title=\"\">Scaling Large Language Models to zero with Ollama</a>\n</li><li><a href=\"https://fly.io/blog/transcribing-on-fly-gpu-machines/\" title=\"\">Transcribing on Fly GPU Machines</a>\n</li></ul>\n\n<p>Depending on factors such as your organization&rsquo;s age and payment history, you may need to go through additional verification steps.</p>\n\n<p>If you&rsquo;ve been experimenting with Fly.io GPUs and have made something cool, let us know on the <a href=\"https://community.fly.io/\" title=\"\">Community Forums</a> or by mentioning us <a href=\"https://hachyderm.io/@flydotio\" title=\"\">on Mastodon</a>! We&rsquo;ll boost the cool ones.</p>",
      "tier": "full",
      "selection_reason": "Major GPU infrastructure becoming widely accessible",
      "audience_value": "New opportunities for AI/ML deployment and scaling",
      "urgency_score": 9,
      "category_tag": "\u2601\ufe0f Enterprise Tech"
    },
    {
      "id": "eecbbbfa60a2d5f005f763fb85561f57",
      "title": "Connecting Language and (Artificial) Intelligence: Princeton\u2019s Tom Griffiths",
      "url": "https://sloanreview.mit.edu/audio/connecting-language-and-artificial-intelligence-princetons-tom-griffiths/",
      "published_date": "2026-02-19T06:59:19.807925",
      "description": "In this bonus episode of the Me, Myself, and AI podcast, Princeton University professor and artificial intelligence researcher Tom Griffiths joins host Sam Ransbotham to unpack The Laws of Thought, his new book exploring how math has been used for centuries to understand how minds \u2014 human and machine \u2014 actually work. Tom walks through [&#8230;]",
      "source": "MIT Sloan Management Review",
      "category": "Management & Leadership",
      "segment": "leaders",
      "source_type": "secondary",
      "raw_content": "<p></p>\n<p>In this bonus episode of the <cite>Me, Myself, and AI</cite> podcast, Princeton University professor and artificial intelligence researcher Tom Griffiths joins host Sam Ransbotham to unpack <cite>The Laws of Thought</cite>, his new book exploring how math has been used for centuries to understand how minds \u2014 human and machine \u2014 actually work. Tom walks through three main frameworks shaping intelligence today \u2014 rules and symbols, neural networks, and probability \u2014 and he explains why modern AI only makes sense when you see how those pieces fit together. The conversation connects cognitive science, large language models, and the limits of human versus machine intelligence. Along the way, Tom and Sam dig into language, learning, and what humans still do better \u2014 like judgment, curation, and metacognition.</p>\n<aside class=\"callout-info\">\n<img alt=\"Tom Griffiths\" src=\"https://sloanreview.mit.edu/wp-content/uploads/2025/12/MMAI-S12-BONUS1-Griffiths-Princeton-headshot-600.jpg\" /></p>\n<h4>Tom Griffiths, Princeton University</h4>\n<p>Tom Griffiths is the author of the new book <cite>The Laws of Thought: The Quest for Mathematical Theory of the Mind</cite> and the Henry R. Luce Professor of Information Technology, Consciousness, and Culture at Princeton University. He also directs Princeton\u2019s Computational Cognitive Science Lab, a research group focused on understanding the mathematical foundations of human cognition, and the Princeton Laboratory for Artificial Intelligence, which supports innovative research efforts in AI and related fields. Griffiths coauthored the book <cite>Algorithms to Live By</cite>, and his award-winning research has been published in <cite>Science</cite>, <cite>Nature</cite>, and the <cite>Proceedings of the National Academy of Sciences</cite>.</p>\n</aside>\n<p>Subscribe to <cite>Me, Myself, and AI</cite> on <a href=\"https://podcasts.apple.com/us/podcast/me-myself-and-ai/id1533115958\" rel=\"noopener\" target=\"_blank\">Apple Podcasts</a> or <a href=\"https://open.spotify.com/show/7ysPBcYtOPVgI6W5an6lup\" rel=\"noopener\" target=\"_blank\">Spotify</a>.</p>\n<h4>Transcript</h4>\n<p><strong>Allison Ryder:</strong> Hi, everyone. While we\u2019re on winter break, we\u2019re dropping a couple of bonus episodes featuring cutting-edge academic researchers. On today\u2019s episode, Sam is joined by professor and director of Princeton\u2019s Computational Cognitive Science Lab, Tom Griffiths. Tom is the author of the forthcoming book <cite>The Laws of Thought</cite> and joins Sam today to speak about AI\u2019s mathematical and linguistic backgrounds. It was a fascinating conversation, and I hope you enjoy it. </p>\n<p><strong>Tom Griffiths:</strong> I\u2019m Tom Griffiths from Princeton University, and you\u2019re listening to <cite>Me, Myself, and AI</cite>. </p>\n<p><strong>Sam Ransbotham:</strong> Welcome to <cite>Me, Myself, and AI</cite>, a podcast from <cite>MIT Sloan Management Review</cite> exploring the future of artificial intelligence. I\u2019m Sam Ransbotham, professor of analytics at Boston College. I\u2019ve been researching data, analytics, and AI at <cite>MIT SMR</cite> since 2014, with research articles, annual industry reports, case studies, and now 12 seasons of podcast episodes. In each episode, corporate leaders, cutting-edge researchers, and AI policy makers join us to break down what separates AI hype from AI success.</p>\n<p>Hi, listeners. Thanks, everyone, for joining us again. Our guest today is Tom Griffiths, professor of psychology and computer science, and the director of the Princeton Laboratory for Artificial Intelligence. Tom has a new book, <cite>The Laws of Thought</cite>, which I suspect our listeners will enjoy learning about. Tom, [it\u2019s] great to have you on the podcast.</p>\n<p><strong>Tom Griffiths:</strong> Thanks, Sam. [It\u2019s] great to be here. </p>\n<p><strong>Sam Ransbotham:</strong> Why don\u2019t we start with \u2026 I think people know it\u2019s kind of fun to be your professor because people know what professors are, but maybe let\u2019s start with a little bit of a bio. Can you give us some background on what your roles are with the lab at Princeton? </p>\n<p><strong>Tom Griffiths:</strong> Princeton, like a lot of other educational institutions, has been trying to figure out how to respond to all of the things that are happening with AI in the world at the moment. The AI lab is the starting point for doing that in terms of thinking about being able to make some targeted investments in research areas where we see potential for [a] transformative impact for AI in a way that\u2019s maybe more nimble than a traditional academic institution might. </p>\n<p><strong>Sam Ransbotham:</strong> There\u2019s a lot going on within universities trying to figure out what exactly all this means, and I guess all of society. But let\u2019s start with <cite>The Laws of Thought</cite>. Can you explain in some simple terms what these laws are and how they relate to human cognition and artificial intelligence? </p>\n<p><strong>Tom Griffiths:</strong> The idea behind the book is \u2026 I think all of us in school learn about the laws of nature, right? These [are] sort of principles of physics or something like that, that tell us about how \u2026 the world around us works. One interesting thing is that the same scientists who hundreds of years ago were trying to figure out what those laws of nature were, using math to describe the physical world, were just as interested in using math to try and understand the mental world, the world inside us. The book is really the story of that effort. </p>\n<p>It turns out understanding our inside world is a bit harder than understanding our outside world. It took us a little bit longer to figure out what the fundamental principles are. It charts the story, from people first introducing this idea of using mathematics to understand the mind, through some of the first discoveries about what kinds of mathematical principles could be used for explaining how minds work \u2014 things like mathematical logic \u2014 to the discovery that that was not going to get us all the way to understanding things like how people learn complex concepts that have fuzzy boundaries, things like languages, and then ideas like artificial neural networks, which are very popular at the moment in artificial intelligence, and then probability and statistics as another approach that really helps us understand why it is that some of those AI methods actually work. </p>\n<p><strong>Sam Ransbotham:</strong> I think you approach this from three different frameworks: rules and symbols is one framework, neural networks is another, and then Bayesian probability is a third. Maybe I\u2019m grossly oversimplifying these three big prongs in the book. Maybe take a minute and explain what each of those pieces are and then, more importantly, how they all weave together. </p>\n<p><strong>Tom Griffiths:</strong> You got it. Those are the three big pieces. Basically the story is that I think the origins of people trying to think about mathematical principles for understanding the mind are really tied up in that rules and symbols approach. That was because that seemed like the first tool that we had that really described something like how thought worked. So if you go back to the origins of logic, the title of the book, <cite>The Laws of Thought</cite>, is a phrase that\u2019s used by George Boole, who was working in the 19th century and sort of figured out some of the first principles of mathematical logic. </p>\n<p>Those principles turned into the principles that underlie our computers today, through the work of Alan Turing and John von Neumann and others. When psychologists were trying to work out how to rigorously study something that you can\u2019t see or touch \u2014 something inside our heads, our minds \u2014 they discovered that those mathematical principles of logic were actually really useful for expressing rigorous, precise hypotheses about how minds work. So that was the starting point for what we now call cognitive science, which is trying to use these mathematical principles to figure out how minds work. </p>\n<p>For a while it seemed like that was going pretty well. It turned out that those systems of rules and symbols worked well for describing things like deductive reasoning, things like problem-solving or planning, things like even the structure of languages through the work of people like Noam Chomsky. But after a while they started to realize that maybe that wasn\u2019t going to be all that we\u2019d need in order to understand how minds work. </p>\n<p>One of the big problems for that rules and symbols approach was explaining learning. It helps us to explain how we reason, helps us to explain what the structures or languages are like, but it doesn\u2019t help us to explain how those things get into our heads in the first place. How do we learn these kinds of strategies for thinking? How do we learn what the structure of those languages are? And it also didn\u2019t work for capturing some of the \u2026 fuzzy boundaries that we see in real concepts. \u2026 If you ask people, \u201cIs an olive a fruit?\u201d people are quite uncertain about [the answer] in a way that\u2019s maybe hard to capture if you\u2019re really just thinking in terms of something like logic. </p>\n<p>In the 1960s-1970s, people started to explore different ways of thinking about the mind in terms of different kinds of mathematics, and thinking about things like maybe our concepts are related to \u2026 we can think about something in the world as being a point in space, where it\u2019s an abstract space that picks out the features that thing has. Maybe a concept is a region in that space. Now a new kind of mathematics is needed for describing these kinds of continuous representations. </p>\n<p>It turns out that when you start thinking in those terms, you end up getting to new ways of thinking about how to solve that learning problem. And that\u2019s where artificial neural networks come in. They\u2019re essentially a way of thinking about how to represent things as points in space and then learn the relationships between those points in space so you can map from one space to another. So that solved a bunch of problems that we had for logic. </p>\n<p>But then we have a bunch of other questions. For example, if we look at things like our large language models [LLMs] today that are very successful in doing all sorts of things like learning language. Really understanding why it is that they\u2019re able to do that requires us to take one more step and think about a different kind of mathematical idea. [Those] ideas come from probability and statistics. Statistics is really the science of inductive inference. It tells us what we can infer from data, and probability theory gives us a tool for understanding how we can work with uncertainty and how we can make inferences from the data that we see. </p>\n<p><strong>Sam Ransbotham:</strong> Is there a fourth one? We\u2019ve got three nice things, and each time you pointed out some aspect of them that [was] strong, and some aspect that led to a limitation. Is there [a] number four out there that we need that we haven\u2019t figured out yet? Or is it just a matter of getting these three mixed in the right proportions and emphasized in the right ways? </p>\n<p><strong>Tom Griffiths:</strong> I think these three are actually pretty good. \u2026 A funny thing that happened to me when I was writing this book is that I\u2019ve been teaching these kinds of ideas to undergraduates for 20 years. When I give my class on computational approaches to understanding cognition, I would normally start that class by saying, \u201cUnlike taking a class in physics or something like that, where you can expect to hear the answers, we\u2019re still figuring these things out. We have good ways of asking the questions [even though] we haven\u2019t quite \u2026 got to those answers.\u201d But I actually think in the last 10 years, in the period that I was working on the book, I think there\u2019s been a change in how much we understand about these things and how well they fit together. We can kind of start to see some glimmers of really figuring out what those laws of thought might look like. </p>\n<p><strong>Sam Ransbotham:</strong> [Are these] laws of thought going to be understanding the borders between these better, or is it going to be some sort of complementarity between them, or some sort of combination in a unique way? </p>\n<p><strong>Tom Griffiths:</strong> Complementarity and combination are, I think, the two ways to think about this. One thing that we\u2019ve started to realize is that there [are] different ways that you can provide an explanation for something like the human mind. So, again, if you\u2019re a physical scientist and you want to explain a phenomenon, say, the behavior of an animal, you could think about explaining that phenomenon at lots of different levels. You could explain it in terms of the environment that the animal is in. You could explain it in terms of the muscles and bones of the animal that are doing certain kinds of things and the nerves and so on. You could explain it in terms of the chemical reactions that are happening to produce those things, or you could explain it in terms of the atoms and molecules that are interacting. There are all of these different levels of analysis that we\u2019re used to thinking about when we think about physical systems. </p>\n<p>One of the insights of cognitive science, something that goes back to a theoretical neuroscientist called David Marr, is the idea that there are similar kinds of levels of analysis that we can think about when we\u2019re trying to understand something like human behavior or the behavior of an intelligent system more generally. </p>\n<p>Marr suggested you could think about this in terms of three levels. The most abstract is what he called the computational level, which is: What\u2019s the abstract problem the system is solving, and what does the solution to that problem look like? And then, more concrete than that, there\u2019s what\u2019s called the algorithmic level, which is: What are the actual processes that are going on inside that system? What [are] the algorithms that are being executed to produce that solution? Then the third is what\u2019s called the implementation level, which is: How is that algorithm implemented inside the brain? </p>\n<p>One important insight here is that these three different systems of mathematics that we\u2019ve been talking about don\u2019t need to be fighting with one another. They can be cooperating by giving us explanations that operate at different levels of analysis. In particular, logic and probability theory are at that most abstract level. They kind of describe how an ideal agent should solve problems that [it] faces, problems like, how do I figure out what\u2019s true based on the things that I already know? Or what inferences can I draw from the things that I\u2019ve seen already? </p>\n<p>The neural networks give us a story about how you can actually create systems that implement different kinds of algorithms that are strategies for approximating solutions to those more abstract, more idealized kinds of mathematical systems. </p>\n<p>So part of the reason why I think maybe three is enough is that logic tells us how to solve what we call deductive problems, problems that require figuring out what\u2019s true when we have all the information. Probability theory tells us how to solve what are called inductive problems, problems where we don\u2019t have all the information and we have to kind of do the best we can to figure out what to do based on what we know. And then our brains somehow solve both of those kinds of problems using things that look very much like the kinds of structures of artificial neural networks. So that combination of three things actually gives us ways of describing the abstract problems we solve as well as the kinds of physical systems that might actually implement solutions to those problems. </p>\n<p><strong>Sam Ransbotham:</strong> Language is a pervasive idea through the book. We can give a nod to my frequent coauthor David Kiron, who\u2019s super into [Ludwig] Wittgenstein and \u201cIf you can\u2019t express it in language, it doesn\u2019t exist\u201d type of ideas. It\u2019s a major function of the book. </p>\n<p>What\u2019s the relationship between maybe the fact that we\u2019re coming up with all this in a moment of English language dominance and would all these things be the same if we\u2019d had them 200 years ago with a French language dominance? We, at the same time, have another layer of mathematical language, which is pervasive. Is coding language another one of these languages that is going to be pervasive? How do all these connections between language and intelligence link up in your mind?</p>\n<p><strong>Tom Griffiths:</strong> Language is a recurring example because it has characteristics that line up with all of these three kinds of mathematical ways of thinking about minds. So the rules and symbols part is what you can think about in terms of a traditional \u2026 way of thinking about grammar in language: A sentence has a noun and a verb, and you know they\u2019re combined in particular ways, and you can move them around in certain kinds of ways. That was this sort of important insight that Noam Chomsky had that really organized most of 20th century linguistics and continues to influence the way people think about these things. </p>\n<p>But that is not enough to explain everything that happens involving language. One of the challenges that Chomsky had was explaining how it is that human children come to speak language, because there wasn\u2019t really a good way to formalize learning in that rules and symbols approach. So he ended up concluding you just had to build it all in. And then, based on the limited information you get, you\u2019ve got enough constraints in the system that the right thing comes out. </p>\n<p>Neural networks offered a way to think about how you could learn things like language from data by showing that even if you had something that was described by a system of rules and symbols, it didn\u2019t need to be implemented as a system of rules and symbols. Some of the key insights that came from [the] early work [of] using neural networks were that you could take grammar and you could have a neural network learn that grammar. It could do so without ever having explicitly represented a noun or a verb or any of those kinds of things. So that gives us a different way of thinking about what language is and a way of understanding how it is that languages might be learned. </p>\n<p>And then, probability theory helps us to understand how, in general, we could imagine those processes of learning working, and sort of understand what it is that they do. So if we think about what language is, it also has this inductive component, where when I say something, you\u2019re trying to figure out what I\u2019m trying to communicate to you, and you\u2019re making an inference from the things that are coming out of my mouth in order to know what\u2019s going on. And your brain is also trying to solve a prediction problem, where it\u2019s trying to cue up, \u201cWhat are the concepts that are likely to come up in this conversation next?\u201d in a way that makes it easy for you to understand the things that we\u2019re saying. </p>\n<p>So if you think about language as a probabilistic object, then we can understand some of the things about how it works and how it\u2019s learned in a way that goes beyond just how we might actually be able to create something like a neural network that instantiates that language. </p>\n<p>When we look at things like large language models, I think they\u2019re actually a great illustration of how these three things come together. First of all, in order to create these systems [that] are able to demonstrate a remarkable amount of intelligence, we need to train them on something [that] has this kind of rules and symbols structure. Large language models aren\u2019t just trained on natural language, and they\u2019re not just trained on English. So you get trained on English. You get trained on French. They also get trained on a large amount of computer code. They\u2019re getting a lot of symbolic structure built into them through that training process. And that\u2019s part of what underlies the intelligence that they manifest. They\u2019re based on these big artificial neural networks. So that\u2019s that second piece. That\u2019s the reason why it\u2019s possible to learn those things. </p>\n<p>And then the third piece is the way that they\u2019re trained is by predicting the next token [that] is going to appear in a sequence, the next word or part of a word that they\u2019re going to see based on all of the words, the parts of words that they\u2019ve seen before. So that training is explicitly setting this up as a probabilistic model. But what it\u2019s trying to do is to learn a probability distribution over sequences of tokens. And what it\u2019s trying to do when you\u2019re interacting with it is make inferences about what sequences of tokens you might want it to generate based on the sequences of tokens that you\u2019ve typed into it. </p>\n<p><strong>Sam Ransbotham:</strong> Let me push back though a little bit. \u2026 You mentioned the rules and symbols. It feels like that\u2019s a place where these current implementations of large language models might be a bit weak. I think one of the examples you gave in your book is that we can pick up a word from the first use, or we can even make up words that should be real words, even if they aren\u2019t really words. We do that based off of an understanding of how those symbols work and how those tokens work. \u2026 People can learn a word on their first hearing. They don\u2019t require the 14 million images of ImageNet to learn. You kind of implied that given this large corpus of knowledge, it would extract those rules and symbols. </p>\n<p>Why not push them a little bit more and give them some rules and symbols to work with? Rather than learn about gravity, you say, \u201cHey, here\u2019s gravity. This is how it works \u2014 always, not just in the four examples that you\u2019ve seen. It works that way all the time.\u201d Where\u2019s that? </p>\n<p>Maybe I\u2019ll push back a little bit to say [that] when I\u2019ve seen some examples of some of the large language models struggling with math, they\u2019ve struggled not with \u201cWhat is 2 plus 2?\u201d Because they\u2019ve seen millions of examples of that. But if you take a superlong number and add it to another superlong number, you tend to get a random, superlong, other number rather than the symbolic representation. You mentioned, I think, in one of the chapters, [that] we understand numbers without ever having seen that specific number before. Is there room for more symbolic processing here, [a] more rules-based approach? </p>\n<p></p>\n<p><strong>Tom Griffiths:</strong> Yeah. I think you highlighted two of the important ways in which current AI systems differ from human cognition, and two of the kinds of things where we can imagine learning things from how human minds work that might make those AI systems better. So those two things [involve] generalization \u2014 being able to generalize in a systematic way beyond the data that they\u2019re provided and learning from small amounts of data. </p>\n<p>I gave the example of kids learning language. A kid learns language on the order of 10 years, whereas the kinds of large language models that are deployed today require more on the order of 10,000 years of continuous speech or something like that in order to reach the level of competence that they reach. </p>\n<p>So those are places where we have opportunities to learn from people. The first of those, this point about generalization, is really about have you formed the right kinds of representations of a domain such that when you start to see things that go beyond the training data you\u2019ve seen, you\u2019re able to then respond to those in ways that are consistent with what you should have learned, in order to represent the domain that you\u2019re operating in? That remains an outstanding problem for language models. </p>\n<p>Part of the way that they\u2019re able to do this is they\u2019ve been exposed to so much linguistic data that they\u2019re able to do very well without necessarily needing to do a lot of extrapolation beyond the kinds of data that they\u2019ve seen before. I have colleagues who have developed paradigms for measuring the extent to which they can extrapolate. They can actually do fairly well. You can do things like have them compose ideas together that they\u2019ve not encountered before and come up with new kinds of things when you put those pieces together. But I think that\u2019s something where there are still limitations in the systematicity of generalization. </p>\n<p>One of the things that surprises us about large language models is they sometimes behave in ways that make very little sense to us. That\u2019s because we\u2019re expecting them to generalize in ways that are like the ways that we\u2019re used to human beings generalizing. The other part of that, the learning part, I think, is perhaps one of the keys to thinking about how we can make systems that generalize better. Because being able to learn from less data very much requires being able to engage in good systematic generalizations. The way we talk about that in machine learning and in cognitive science is in terms of what we call inductive bias. </p>\n<p>Inductive bias is what the learner brings to a problem. That means that they favor some solutions over others. So if you see only a limited amount of data, there are many possible ways that you could explain [the] data that you saw. How do you choose between those many possible explanations? If you\u2019re learning a language, how do you choose which structure of the language you\u2019re going to infer?</p>\n<p>Inductive bias is the thing that breaks ties there. It tells us, \u201cYou should think about it this way rather than this way.\u201d Humans undoubtedly have a systematic set of inductive biases that are not instantiated in our neural networks. One of the important challenges for both AI and cognitive science is figuring out what those human inductive biases are and figuring out how to put them into things like these kinds of neural network systems. That\u2019s something that I work on in my lab. It\u2019s something that a lot of cognitive scientists are actively thinking about at the moment. </p>\n<p><strong>Sam Ransbotham:</strong> One of the things I enjoyed was with each chunk in your book, you take a little bit of a historical path through how we got to this point. You mentioned before Boole and the development of Boolean logic and Bayes, and how that added to the equation. Now I\u2019m going to be mean here and say that \u201cOK, these are some summaries of historical information leading to a path.\u201d My mean part is, \u201cWhat did you, Tom the human, add to this book?\u201d </p>\n<p>Were I to summarize the development of language or the development of Bayesian thought or probabilistic reasoning, and I put that in an LLM, and I ask, \u201cGive me four paragraphs about that.\u201d What did you the human add to this equation, to this book that would not have been done by that summarization process? </p>\n<p><strong>Tom Griffiths:</strong> There are a couple of things. One thing is the book actually involves a lot of primary source research. The story of where the book came from is partly that I realized that our field of cognitive science is one where, at the time when I started this project, many of the people who were there at the sort of birth of modern cognitive science in the 1950s were still alive, and I was able to go around and interview them and collect their stories. So a lot of the book is really telling those stories and using those to explain where those ideas come from. </p>\n<p>But in terms of the writing, I think the thing that I am able to do as a human author is engage in what we call theory of mind in cognitive science. This is me thinking about what it is that is going to make sense to a reader and that\u2019s going to be appealing, not just as a story but also clear in terms of conveying those ideas and putting those together in a structure that makes sense for the reader. I\u2019m not going to claim that\u2019s something only humans are going to be able to do forever. I think, at the moment, it\u2019s something that still humans are better at doing than the current models that we have. But we actually have been doing experiments in my lab and showing that large language models are not bad at putting together a curriculum for people to help them learn a concept, sort of figuring out, \u201cYou need to introduce this simpler idea first and then this other idea, and then it can put them together and so on.\u201d So they\u2019re definitely able to extract some of the structures that we use for solving these problems through our own intuitions about pedagogy and theory of mind and so on. </p>\n<p><strong>Sam Ransbotham:</strong> Maybe a different thing is that there [are] a lot of stories that you didn\u2019t include in the book. There\u2019s a lot of curation that\u2019s happening. That\u2019s one thing that I guess I\u2019m thinking about a lot. We have the machines capable of [having] effectively infinite memory of all possible stories. There\u2019s definitely value in you stitching out and saying, \u201cThese were important for this reason, and this is important for another reason,\u201d because these were some big steps. In doing so you\u2019ve inherently had to leave out some things. There\u2019s a curation going on there. I feel like that\u2019s something that you knew what to focus on that was important for the story, and maybe, like you say, the machines aren\u2019t quite there for that. </p>\n<p><strong>Tom Griffiths:</strong> This is actually, I think, a good connection to a question that I get asked a lot: What\u2019s going to happen to the kinds of jobs that humans do? Because we\u2019ve previously seen technology replace certain kinds of labor \u2014 physical labor [of] various kinds, manufacturing, things like that. And now we\u2019re seeing machines start to replace cognitive labor, which is different. </p>\n<p>As a psychologist, one of the things that I think about is there\u2019s another kind of labor that maybe is going to become even more important, which is metacognitive labor. This is what you\u2019re doing as a manager when you\u2019re thinking about, \u201cWho is going to be the best employee to do this job, and how should I describe it to them in order to ask them to do it so that it ends up being done in a way that\u2019s effective?\u201d Or thinking about for yourself: \u201cWhat strategy should I use to solve a problem?\u201d and \u201cWhat\u2019s the right way to approach this problem?\u201d</p>\n<p>What we\u2019re starting to do with these machines is outsource the cognitive component of the work. They\u2019re able to do some of that for us, but we\u2019re still having to do a lot of the metacognitive part. So that curation process you\u2019re describing is a good example of something [that] is not telling the story; it\u2019s figuring out the structure around that. That\u2019s going to be the analogs of the prompt that you\u2019d be providing to the AI system to maybe tell that story for you. </p>\n<p><strong>Sam Ransbotham:</strong> Are there other things besides metacognition? What else is in that list? </p>\n<p><strong>Tom Griffiths:</strong> The first thing, I would say, is metacognition is quite a big item. I\u2019m giving it the same status as physical labor and cognition. There are lots of people today whose jobs are metacognitive jobs, in management roles. And I think that\u2019s going to be a skill set that becomes more and more important. </p>\n<p>One of the things that happens in graduate school \u2014 well at least when I work with my graduate students \u2014 is not just learning how to do research but also learning how to think about what a good research project is. What I say to my students is there\u2019s a difference between the projects that we could do and the projects that we should do. Figuring out how to prioritize and work out what the best ideas are [is] one of the hardest things for people to learn, and that\u2019s part of why it takes quite a long time to do a Ph.D. I think that kind of skill set is going to be one that becomes increasingly valuable as it becomes easier to execute on these kinds of things. </p>\n<p><strong>Sam Ransbotham:</strong> One of the things that you mentioned and others have mentioned, too, is some of these constraints that are constraints on human intelligence are not the same as the constraints on machines. \u2026 What are some of those constraints [where] you see differences between machines and humans? And then what are the implications of there not being those constraints in the future? </p>\n<p><strong>Tom Griffiths:</strong> The three that I would normally highlight are: We have limited lifespans, limited time in this world. That means limited data we can learn from, limited compute. So [we have] limited cognitive resources, because we just carry around 2 or 3 pounds of neural tissue, and we have to do everything with that. </p>\n<p>And then, [we have] limited bandwidth for communication. If I want to share some of the data or compute that I have with you, I have to do it through this very inefficient mechanism that we\u2019re using right now of making honking noises. That set of constraints, I would say, [is] what makes human intelligence what it is, right? \u2026 We\u2019ve evolved minds in response to those constraints. </p>\n<p>If you look at what\u2019s going on for AI systems, really none of those things are true. We are able to turn up the knob of compute as high as it can go. It\u2019s somewhat limited at the moment because we\u2019re running out of money and energy resources to be able to keep building data centers. But that\u2019s something where the expectation that we should have is that we should, over time, continue to be able to have greater compute capacity for training the systems. That translates into being able to train systems on much more data, and all of [our] breakthrough AI systems have been trained on more data than human beings will ever experience. </p>\n<p>AlphaGo [has] many human lifetimes of playing [the] game of Go, and our language models today have many human lifetimes of linguistic data. </p>\n<p>And then bandwidth: You can take one AI system that\u2019s been trained on one set of things and then train it on some more things, or transfer the weights that it has between machines or split them up in all these ways. This idea of foundation models is that you can have one model and then copy it many times and then fine-tune those to solve different problems, and that\u2019s just fundamentally different from humans. For those reasons, I think we\u2019re going to see a meaningful divergence between the kinds of minds that humans are and the kinds of minds that the AI systems are. We shouldn\u2019t expect them to be the same because they\u2019re operating under different constraints, but we can still learn meaningful things about one another by comparing these different species when we take into account the fact that we\u2019ve evolved in these different environments. </p>\n<p><strong>Sam Ransbotham:</strong> I liked your \u201cWe communicate by making honking noises to each other.\u201d Is that holding us back? Is there a need for a language 3.0 type of a thing to move us to better bandwidth? </p>\n<p><strong>Tom Griffiths:</strong> Ren\u00e9 Descartes wrote about this idea all the way back when he was starting to think about math for the physical world. He talked about this idea that maybe there\u2019s a similar sort of structure to language. You could imagine creating a language where just hearing somebody say something in that language, you know what that thing is. </p>\n<p>In the same way that if I say \u201c10,000, 500, and 42,\u201d even though that\u2019s not a string you\u2019ve ever heard before, it tells you exactly the thing that it\u2019s referring to, you can sort of figure it out from the expression. </p>\n<p>[Gottfried] Leibniz was also obsessed with this idea. He had this idea that he called the universal character, which was a language in which you would be able to express things and then perform some mathematical operations on those things, and then figure out what the consequences of those things were. Just by expressing things in that language, you would know whether those things were true or false, and whether they were compatible with other things, and so on. That\u2019s what motivated him to think about mathematical logic. There was this spirit that traced through the book in terms of thinking about what the consequences of having these kinds of mathematical formalisms for understanding thought can be. </p>\n<p>So it\u2019s an interesting question: Can you turn all of that back around and come up with better languages for humans? There\u2019s a little bit of work along these lines. Bean Kim and colleagues at Google have a paper [that] looks at neologisms for language models, where it\u2019s looking at what are places where introducing a new term can help a language model capture a concept that\u2019s relevant to the operations that model is doing but also help us understand what it is that the language model is doing? </p>\n<p>I think you can imagine building better interfaces between us and AI systems by allowing language to evolve in ways that capture concepts that are relevant to those systems. That sounds like an interesting cognitive science problem. </p>\n<p><strong>Sam Ransbotham:</strong> We may be headed that way anyway by communicating with emojis. It doesn\u2019t convey well on this audio format, but the chapter you\u2019ve got about the representation of those universal symbols and how those worked, I didn\u2019t know about that beforehand. So I was able to pick up on that. One of the things on your website says \u2014 and I\u2019ll quote you \u2014 \u201cIt\u2019s natural to ask, \u2018What makes human intelligence special?\u2019\u201d So if it\u2019s natural, let me ask it: What makes human intelligence special? </p>\n<p><strong>Tom Griffiths:</strong> I would say those things that I mentioned, the constraints, are the things that really shape the nature of human intelligence. But I think it\u2019s maybe a mistake to think about that as being special. Rather, maybe we should think about that as being different. I think there\u2019s a tendency that people have when they talk about AI to think about intelligence being a one-dimensional scale. So people ask questions like, \u201cHave we made superintelligence?\u201d \u201cHave we made whatever the next iteration of this is?\u201d I think that\u2019s a very limited way of thinking about what it is minds are and what intelligence is. </p>\n<p>I think it\u2019s maybe better to think about intelligence as being shaped by the kinds of problems that minds have to solve and the kinds of constraints that they have to solve those problems under. That\u2019s maybe more like a sort of evolutionary way of looking at things, where we can imagine minds being shaped by those problems and constraints. But it\u2019s something where if we apply that to thinking about AI, we\u2019re going to have expectations that humans and AI systems are going to be meaningfully different. </p>\n<p>There are ways that you can imagine making AI systems better by incorporating things that come from people. That\u2019s part of what makes it exciting to think about these things from the perspective of cognitive science. But I don\u2019t think it\u2019s obligatory that we do that, because we could come up with completely different ways of solving those problems that make it possible for us to make AI systems that can do the things that we want AI systems to do, without them necessarily having to be exactly like us. </p>\n<p>I think when people talk about [artificial general intelligence] and wanting to make systems that are like people but better in whatever way, my reaction to that is to say, \u201cWell, maybe we should just think about them as being different from us but having a set of capabilities that that are perhaps harmonious with and complementary to the abilities that we have as humans.\u201d</p>\n<p>I think another thing that we should think about when we\u2019re trying to think about these differences between humans and AI systems is exactly what it is that we want to use our AI systems for. In general, we have a higher bar for the behavior of our AI systems than we have for a human being. That\u2019s appropriate, right? If we\u2019re going to be deploying a system intentionally and we could make it better, we should try and make it better. </p>\n<p>I think some of these things, like reasoning and being able to solve math problems, and so on, that are within the capacity of AI systems but are in some ways a challenge for our current large language model-based systems, are places where there\u2019s opportunities to use what people call a neuro-symbolic approach, where you build in aspects of logic or other kinds of mathematical tools that these systems can use to be able to do things that make them better than the baseline language models are. That\u2019s an important thing to do if you want to make better AI systems.</p>\n<p>It\u2019s not necessarily something that\u2019s going to help us understand human minds better. Human minds are built out of the same sort of messy stuff that we\u2019re trying to build our large language models out of and mess up in the same kinds of ways as those models when you have them solve math problems or do other kinds of things. Part of that is suggesting that, again, there\u2019s a kind of divergence that could happen where we need to do a bunch more work to figure out how to make our AI systems reliable in ways \u2026 in order to be deployable, but we have enough of the basic principles figured out that we still have good insight into human cognition already.</p>\n<p><strong>Sam Ransbotham:</strong> What I like about that is it speaks to the idea that LLMs, though wonderful, [are] not necessarily the end of the chapter of the book. There are whole different ways of approaching these problems that may or may not have strengths and weaknesses. Just like you mentioned with the growth of the different approaches, whether it\u2019s symbols and rules or Bayesian logic or neural networks, we can realize some limitations and then build on them and try to combine those in different ways. So maybe there\u2019s hope for some entirely new approaches. </p>\n<p>This is all interesting. Given these laws of thought, what should our listeners change about anything that they do tomorrow? </p>\n<p><strong>Tom Griffiths:</strong> I think one thing is it might change the way that you think about what AI systems are doing. I think we all have a model of how minds work that\u2019s based on interacting with other humans. And when we think about our AI systems, we think about them using the same set of tools that we use for thinking about other humans. And that can be \u2026 misleading in a few ways. </p>\n<p>One way is that we can have incorrect assumptions about how they\u2019re going to generalize. We say, \u201cThis AI system solved this olympiad math problem that\u2019s extremely hard.\u201d And then if we think about a human being who is able to do that, you\u2019d say, \u201cOh, they must be incredibly smart. They must be able to do all sorts of things that I can\u2019t do.\u201d But in fact, that\u2019s a relatively narrow piece of the profile of these systems. In some ways, getting better at solving these kinds of problems might make them less good at solving other kinds of problems, and there\u2019s a kind of balancing act that goes on there. </p>\n<p>So when you try and make generalizations [such as], \u201cIf this kind of machine can solve this problem, it\u2019s going to be able to solve this other problem,\u201d I think if you approach it as not something that\u2019s like us but rather something that\u2019s shaped by the way in which it\u2019s been trained and the constraints that it operates under, and all these other kinds of things, our expectations about how the systems are going to generalize would be different. So that might make you a little more pessimistic about timelines for building [artificial general intelligence], right? We shouldn\u2019t make the same generalizations from the peaks, covering the entire surface of the abilities of these systems. </p>\n<p>I think the other thing it might do is help us to imagine futures that are perhaps less scary in terms of the way that we imagine these systems affecting human societies. If we start thinking about AI systems as being different from us, then that suggests this view of complementarity, where there are going to be things that you\u2019re going to be better at, and there are going to be things the AI is going to be better at. Just like you try and figure out how to divide jobs up across people who have different kinds of abilities, thinking about how it is that we\u2019re going to divide the kinds of things that we want to be able to accomplish between humans who can do certain kinds of things and AI systems that can do other kinds of things is maybe a healthier way of thinking about this than sort of imagining that we\u2019re going to be completely replaced. </p>\n<p><strong>Sam Ransbotham:</strong> It\u2019s fascinating talking to you. We\u2019ve been talking about the <cite>Laws of Thought</cite>, which is coming out [on] Feb. 10. Tom, thanks for taking the time to talk with us today. </p>\n<p><strong>Tom Griffiths:</strong> Thank you. </p>\n<p><strong>Sam Ransbotham:</strong> Thanks for listening today. On our next episode, I\u2019ll speak with Nobel Prize-winning economist Daron Acemoglu about his research at MIT. Please join us.</p>\n<p><strong>Allison Ryder:</strong> Thanks for listening to <cite>Me, Myself, and AI</cite>. Our show is able to continue, in large part, due to listener support. Your streams and downloads make a big difference. If you have a moment, please consider leaving us an Apple Podcasts review or a rating on Spotify. And share our show with others you think might find it interesting and helpful.</p>\n<p></p>",
      "tier": "full",
      "selection_reason": "Deep dive into fundamental AI theory and future directions",
      "audience_value": "Strategic understanding of AI's theoretical foundations",
      "urgency_score": 8,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "d9bd80683ea314f624b23026acb33e15",
      "title": "Videos: Intro to Vitess\u2014its powerful capabilities and how to get started",
      "url": "https://planetscale.com/blog/videos-intro-to-vitess-its-powerful-capabilities-and-how-to-get-started",
      "published_date": "2026-02-19T06:59:41.764440",
      "description": "This video playlist featuring Vitess co-creator Sugu Sougoumarane is an excellent resource to learn more about the features and capabilities of open source Vitess.",
      "source": "Blog \u2014 PlanetScale",
      "category": "Database & Backend",
      "segment": "builders",
      "source_type": "primary",
      "raw_content": "In 2020, we launched our first video series about Vitess to help individuals learn more about its features and capabilities. For those new to Vitess, it is an open source horizontal sharding framework for MySQL, developed at YouTube to help them keep up with their massive scale. It was later donated to the CNCF and now sits among Kubernetes, Prometheus, and others as a graduated project.\nThe videos feature Sugu Sougoumarane, co-creator of Vitess and CTO of PlanetScale. At a glance, these short videos are in a FAQ format and cover these topics:\nHow Vitess was tested on Borg at YouTube\nWhat attributes make Vitess cloud-native and how does it run on Kubernetes?\nWhat is VReplication?\nWhat can be done with VReplication?\nReal time rollups explained\nIn 2024, we released a free course on getting up-and-running with Vitess.This course covers what Vitess is, and guides you though how to set up your own cluster, both in an unsharded and sharded configuration.Check it out.\nIf you are interested in getting started with Vitess, join the Vitess Slack community, try it out for yourself with the quickstart guide, or check out our newly open-sourced Vitess Operator for Kubernetes.",
      "tier": "full",
      "selection_reason": "Breakthrough in video-based AI capabilities",
      "audience_value": "Technical insights into next-gen video AI applications",
      "urgency_score": 8,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "3015ee8a36b17d84e00ed57a41e1b36f",
      "title": "Robot Dogs Are on Going on Patrol at the 2026 World Cup in Mexico",
      "url": "https://www.wired.com/story/robot-dogs-are-on-going-on-patrol-at-the-2026-world-cup-in-mexico/",
      "published_date": "2026-02-19T06:59:22.324502",
      "description": "The Mexican city of Guadalupe, which will host portions of the 2026 World Cup, recently showed off four new robot dogs that will help provide security during matches at BBVA Stadium.",
      "source": "WIRED",
      "category": "AI & Innovation",
      "segment": "leaders",
      "source_type": "secondary",
      "raw_content": "The Mexican city of Guadalupe, which will host portions of the 2026 World Cup, recently showed off four new robot dogs that will help provide security during matches at BBVA Stadium.",
      "tier": "full",
      "selection_reason": "Real-world deployment of advanced robotics",
      "audience_value": "Practical implementation of autonomous systems",
      "urgency_score": 8,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "5c29f7c09ca7f8aa896d4b00a76bf609",
      "title": "In our latest podcast, hear how the \u201cSmoke Jumpers\u201d team brings Gemini to billions of people.",
      "url": "https://blog.google/products-and-platforms/products/gemini/release-notes-podcast-smokejumpers/",
      "published_date": "2026-02-19T06:59:28.512024",
      "description": "<img src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/thumbnails_EP24_002_ccRelease_N.max-600x600.format-webp.webp\" />Bringing Gemini to billions of users requires a massive, coordinated infrastructure effort. In the latest episode of the Google AI: Release Notes podcast, host Logan Kil\u2026",
      "source": "Google Blog",
      "category": "AI Research & Labs",
      "segment": "innovators",
      "source_type": "primary",
      "raw_content": "",
      "tier": "full",
      "selection_reason": "Inside look at Gemini's infrastructure deployment",
      "audience_value": "Technical insights into scaling AI systems",
      "urgency_score": 9,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "00d47c7482b5edd3ba93c2d2daa66c17",
      "title": "How to train a new language model from scratch using Transformers and Tokenizers",
      "url": "https://huggingface.co/blog/how-to-train",
      "published_date": "2026-02-19T06:59:31.218887",
      "description": "",
      "source": "Hugging Face - Blog",
      "category": "ML Community & Tools",
      "segment": "innovators",
      "source_type": "primary",
      "raw_content": "",
      "tier": "quick",
      "selection_reason": "Essential technical guide for AI model development",
      "audience_value": "Practical implementation knowledge for AI systems",
      "urgency_score": 7,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "78b038b0ef44b636f59c1621cab0b756",
      "title": "How to generate text: using different decoding methods for language generation with Transformers",
      "url": "https://huggingface.co/blog/how-to-generate",
      "published_date": "2026-02-19T06:59:31.218865",
      "description": "",
      "source": "Hugging Face - Blog",
      "category": "ML Community & Tools",
      "segment": "innovators",
      "source_type": "primary",
      "raw_content": "",
      "tier": "quick",
      "selection_reason": "Advanced techniques for language model deployment",
      "audience_value": "Technical optimization strategies for AI systems",
      "urgency_score": 7,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "d6d250b148d889c3734d533bb0c97064",
      "title": "7 Advanced Feature Engineering Tricks Using LLM Embeddings",
      "url": "https://machinelearningmastery.com/7-advanced-feature-engineering-tricks-using-llm-embeddings/",
      "published_date": "2026-02-19T06:59:37.255101",
      "description": "You have mastered model.",
      "source": "MachineLearningMastery.com",
      "category": "AI & Machine Learning",
      "segment": "builders",
      "source_type": "secondary",
      "raw_content": "You have mastered model.",
      "tier": "quick",
      "selection_reason": "Advanced feature engineering techniques for LLMs",
      "audience_value": "Cutting-edge ML optimization strategies",
      "urgency_score": 7,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "fbf9b038b0c6fa1abfdaf5ebff289d33",
      "title": "Export Your ML Model in ONNX Format",
      "url": "https://machinelearningmastery.com/export-your-ml-model-in-onnx-format/",
      "published_date": "2026-02-19T06:59:37.255078",
      "description": "When building machine learning models, training is only half the journey.",
      "source": "MachineLearningMastery.com",
      "category": "AI & Machine Learning",
      "segment": "builders",
      "source_type": "secondary",
      "raw_content": "When building machine learning models, training is only half the journey.",
      "tier": "quick",
      "selection_reason": "Essential guide for ML model deployment",
      "audience_value": "Technical implementation knowledge",
      "urgency_score": 6,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    },
    {
      "id": "337e5bc28fed8d4c0f95dc57c4537acc",
      "title": "There is no longer any such thing as Computer Security",
      "url": "https://blog.codinghorror.com/there-is-no-longer-any-such-thing-as-computer-security/",
      "published_date": "2026-02-19T06:59:34.257088",
      "description": "<p>Remember &#x201c;cybersecurity&#x201d;?</p><figure class=\"kg-card kg-image-card\"><img alt=\"its-cybersecurity-yay\" class=\"kg-image\" height=\"696\" src=\"https://blog.codinghorror.com/content/images/2018/09/its-cybersecurity-yay.jpg\" width=\"1115\" /></figure><p>Mysterious hooded computer guys doing mysterious hooded computer guy... things! Who knows what kind of naughty digital mischief they might be up to?</p><p>Unfortunately, we now live in a world where this kind of digital mischief is literally rewriting the world&#x2019;s history. For proof</p>",
      "source": "Coding Horror",
      "category": "Developer & Engineering",
      "segment": "builders",
      "source_type": "primary",
      "raw_content": "<img alt=\"There is no longer any such thing as Computer Security\" src=\"https://blog.codinghorror.com/content/images/2025/02/its-cybersecurity-yay.jpg\" /><p>Remember &#x201c;cybersecurity&#x201d;?</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"696\" src=\"https://blog.codinghorror.com/content/images/2018/09/its-cybersecurity-yay.jpg\" width=\"1115\" /></figure><p>Mysterious hooded computer guys doing mysterious hooded computer guy... things! Who knows what kind of naughty digital mischief they might be up to?</p><p>Unfortunately, we now live in a world where this kind of digital mischief is literally rewriting the world&#x2019;s history. For proof of that, you need look no further than this single email that was sent March 19th, 2016.</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"656\" src=\"https://blog.codinghorror.com/content/images/2018/09/podesta-hack-email-text.png\" width=\"613\" /></figure><p>If you don&#x2019;t recognize what this is, it is a&#xa0;<a href=\"https://blog.codinghorror.com/phishing-the-forever-hack/\">phishing email</a>.</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"728\" src=\"https://blog.codinghorror.com/content/images/2025/02/image-31.png\" width=\"1092\" /></figure><p>This is by now a very, very famous phishing email, arguably the most famous of all time. But let&#x2019;s consider&#xa0;how this email even got sent to its target in the first place:</p><ul><li>An attacker slurped up lists of any public emails of 2008 political campaign staffers.</li><li>One 2008 staffer was&#xa0;<em>also</em>&#xa0;hired for the 2016 political campaign.</li><li>That particular staffer had non-public campaign emails in their address book, and one of them was a powerful key campaign member with an extensive email history.</li></ul><p>On successful phish leads to an even wider address book attack net down the line. Once they gain access to a person&#x2019;s inbox, they use it to prepare to their next attack. They&#x2019;ll harvest existing email addresses, subject lines, content, and attachments to construct plausible looking boobytrapped emails and mail them to all of&#xa0;<em>their</em>&#xa0;contacts. How sophisticated and targeted to a particular person this effort is determines whether it&#x2019;s so-called &#x201c;spear&#x201d; phishing or not.</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"742\" src=\"https://blog.codinghorror.com/content/images/2018/09/phishing-vs-spear-phishing.png\" width=\"1972\" /></figure><p>In this case is it was not at all targeted. This is a remarkably unsophisticated, absolutely generic routine phishing attack. There is zero focused attack effort on display here. But note the target did&#xa0;<em>not</em>&#xa0;immediately click the link in the email!</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"989\" src=\"https://blog.codinghorror.com/content/images/2018/09/podesta-hack-email-link-1.png\" width=\"1696\" /></figure><p>Instead, he did exactly what you&#x2019;d want a person to do in this scenario:&#xa0;<strong>he emailed IT support and asked if this email was valid.</strong>&#xa0;But IT made&#xa0;a <a href=\"https://www.nytimes.com/2016/12/13/us/politics/russia-hack-election-dnc.html\" rel=\"noreferrer\">fatal mistake in their response</a>.</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"610\" src=\"https://blog.codinghorror.com/content/images/2018/09/podesta-it-support-response.png\" width=\"1212\" /></figure><p>Do you see it? Here&#x2019;s the kicker:</p><blockquote>Mr. Delavan, in an interview, said that his bad advice was a result of a typo: He knew this was a phishing attack, as the campaign was getting dozens of them. He said&#xa0;<strong>he had meant to type that it was an &#x201c;illegitimate&#x201d; email, an error that he said has plagued him ever since.</strong></blockquote><p>One word. He got&#xa0;<em>one</em>&#xa0;word wrong. But what a word to get wrong, and in the first sentence! The email did provide the proper Google address to reset your password. But the lede was already buried since the first sentence said &#x201c;legitimate;&#x201d; the phishing link in that email was then clicked. And the rest is literally history.</p><p>What&#x2019;s even funnier (well, in the way of gallows humor, I guess) is that public stats were left enabled for that bit.ly tracking link, so you can see exactly what crazy domain that &#x201c;Google login page&#x201d; resolved to, and that it was clicked exactly twice, on the same day it was mailed.</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"715\" src=\"https://blog.codinghorror.com/content/images/2018/09/bitly-podesta-tracking-link.png\" width=\"1120\" /></figure><p>As I said, these were not exactly sophisticated attackers. So yeah, in&#xa0;<em>theory</em>&#xa0;an attentive user could pay attention to the browser&#x2019;s address bar and notice that after clicking the link, they arrived at</p><p><code>http://myaccount.google.com-securitysettingpage.tk/security/signinoptions/password</code></p><p>instead of</p><p><code>https://myaccount.google.com/security</code></p><p>Note that the phishing URL is carefully constructed so the most &#x201c;correct&#x201d; part is at the front, and weirdness is sandwiched in the middle. Unless you&#x2019;re paying very close attention and your address bar is long enough to expose the full URL, it&#x2019;s&#x2026; tricky. See this 10 second video for a dramatic example.</p><figure class=\"kg-card kg-video-card kg-width-regular\">\n            <div class=\"kg-video-container\">\n                <video height=\"1080\" poster=\"https://img.spacergif.org/v1/1920x1080/0a/spacer.png\" preload=\"metadata\" src=\"https://storage.ghost.io/c/eb/aa/ebaa2665-01a8-4415-8825-69d1f0e8fd19/content/media/2025/02/twitter-phishing-video.mp4\" width=\"1920\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\">\n                        <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\">\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\">\n                            <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\">\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\">\n                            <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <rect height=\"22\" rx=\"1.5\" ry=\"1.5\" width=\"7\" x=\"3\" y=\"1\">\n                                <rect height=\"22\" rx=\"1.5\" ry=\"1.5\" width=\"7\" x=\"14\" y=\"1\">\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:10</span>\n                        </div>\n                        <input class=\"kg-video-seek-slider\" max=\"100\" type=\"range\" value=\"0\" />\n                        <button class=\"kg-video-playback-rate\">1&#xd7;</button>\n                        <button class=\"kg-video-unmute-icon\">\n                            <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\">\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\">\n                            <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\">\n                            </svg>\n                        </button>\n                        <input class=\"kg-video-volume-slider\" max=\"100\" type=\"range\" value=\"100\" />\n                    </div>\n                </div>\n            </div>\n            \n        </figure><p>(<s>And if you think that one&#x2019;s good, check out&#xa0;this one.</s> Don&#x2019;t forget all the Unicode look-alike trickery you can pull, too.) </p><p>I originally wrote this post as a presentation for the Berkeley Computer Science Club back in March, and at that time I gathered a list of public phishing pages I found on the web.</p><p><code>nightlifesofl.com<br />ehizaza-limited.com<br />tcgoogle.com<br />appsgoogie.com<br />security-facabook.com</code></p><p>Of those five examples from 6 months ago, one is completely gone, one loads just fine, and three present an appropriately scary red interstitial warning page that strongly advises you not to visit the page you&#x2019;re trying to visit, courtesy of Google&#x2019;s&#xa0;<a href=\"https://developers.google.com/safe-browsing/\" rel=\"noopener noreferrer\">safe browsing API</a>. But of course this kind of shared blacklist domain name protection will be completely useless on any fresh phishing site. (Don&#x2019;t even get me started on how&#xa0;<a href=\"https://blog.codinghorror.com/blacklists-dont-work/\">blacklists have never really worked</a>&#xa0;anyway.)</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"720\" src=\"https://blog.codinghorror.com/content/images/2018/09/google-login-phishing-page.png\" width=\"602\" /></figure><p>It doesn&#x2019;t exactly require a PhD degree in computer science to phish someone:</p><ul><li>Buy a crazy long, realistic looking domain name.</li><li>Point it to a cloud server somewhere.</li><li>Get a free HTTPS certificate courtesy of&#xa0;<a href=\"https://blog.codinghorror.com/lets-encrypt-everything/\">our friends at Let&#x2019;s Encrypt</a>.</li><li>Build a realistic copy of a login page that silently transmits everything you type in those login fields to you &#x2013; perhaps even in real time, as the target types.</li><li>Harvest email addresses and mass mail a plausible looking phishing email with your URL.</li></ul><p>I want to emphasize that although clearly mistakes were made in this specific situation, none of the people involved here were amateurs. They had training and experience. They were working with IT and security professionals. Furthermore, they&#xa0;<a href=\"https://www.apnews.com/dea73efc01594839957c3c9a6c962b8a\" rel=\"noopener noreferrer\">knew digital attacks were incoming</a>.</p><blockquote>The&#x2026; campaign was no easy target; several former employees said the organization put particular stress on digital safety.<br /><br />Work emails were protected by two-factor authentication, a technique that uses a second passcode to keep accounts secure. Most messages were deleted after 30 days and staff went through phishing drills. Security awareness even followed the campaigners into the bathroom, where someone put a picture of a toothbrush under the words: &#x201c;You shouldn&#x2019;t share your passwords either.&#x201d;</blockquote><p>The campaign itself used two factor auth extensively, which is why personal Gmail accounts were targeted, because they were less protected.</p><p>The key takeaway here is that&#xa0;<strong>it&#x2019;s basically impossible, statistically speaking, to prevent your organization from being phished.</strong></p><p>Or is it?</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"440\" src=\"https://blog.codinghorror.com/content/images/2025/02/image-32.png\" width=\"440\" /></figure><p>Nobody is doing better work in this space right now than Maciej Ceglowski and Tech Solidarity. Their list of&#xa0;<a href=\"https://techsolidarity.org/resources/basic_security.htm\" rel=\"noopener noreferrer\">basic security precautions</a>&#xa0;for non-profits and journalists is pure gold and has been vetted by many industry professionals with security credentials that are actually impressive, unlike mine. Everyone should read this list very closely, point by point.</p><p>Everyone?</p><p>Computers, courtesy of smartphones, are&#xa0;now such a <a href=\"https://blog.codinghorror.com/can-software-make-you-less-racist/\">pervasive part of average life</a>&#xa0;for average people that&#xa0;<strong>there is no longer any such thing as &#x201c;computer security.&#x201d; There is only&#xa0;<em>security</em>.</strong>&#xa0;In other words, these are normal security practices&#xa0;<em>everyone</em>&#xa0;should be familiar with. Not just computer geeks. Not just political activists and politicians. Not just journalists and nonprofits.</p><figure class=\"kg-card kg-video-card kg-width-regular\">\n            <div class=\"kg-video-container\">\n                <video height=\"338\" poster=\"https://img.spacergif.org/v1/480x338/0a/spacer.png\" preload=\"metadata\" src=\"https://storage.ghost.io/c/eb/aa/ebaa2665-01a8-4415-8825-69d1f0e8fd19/content/media/2025/02/gary-oldman-everyone.mp4\" width=\"480\"></video>\n                <div class=\"kg-video-overlay\">\n                    <button class=\"kg-video-large-play-icon\">\n                        <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                            <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\">\n                        </svg>\n                    </button>\n                </div>\n                <div class=\"kg-video-player-container\">\n                    <div class=\"kg-video-player\">\n                        <button class=\"kg-video-play-icon\">\n                            <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <path d=\"M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z\">\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-pause-icon kg-video-hide\">\n                            <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <rect height=\"22\" rx=\"1.5\" ry=\"1.5\" width=\"7\" x=\"3\" y=\"1\">\n                                <rect height=\"22\" rx=\"1.5\" ry=\"1.5\" width=\"7\" x=\"14\" y=\"1\">\n                            </svg>\n                        </button>\n                        <span class=\"kg-video-current-time\">0:00</span>\n                        <div class=\"kg-video-time\">\n                            /<span class=\"kg-video-duration\">0:02</span>\n                        </div>\n                        <input class=\"kg-video-seek-slider\" max=\"100\" type=\"range\" value=\"0\" />\n                        <button class=\"kg-video-playback-rate\">1&#xd7;</button>\n                        <button class=\"kg-video-unmute-icon\">\n                            <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <path d=\"M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z\">\n                            </svg>\n                        </button>\n                        <button class=\"kg-video-mute-icon kg-video-hide\">\n                            <svg viewBox=\"0 0 24 24\" xmlns=\"http://www.w3.org/2000/svg\">\n                                <path d=\"M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z\">\n                            </svg>\n                        </button>\n                        <input class=\"kg-video-volume-slider\" max=\"100\" type=\"range\" value=\"100\" />\n                    </div>\n                </div>\n            </div>\n            \n        </figure><p><em>Everyone.</em></p><p>It is a fair bit of reading, so because I know you are just as lazy as I am, and I am&#xa0;<em>epically</em>&#xa0;lazy, let me summarize what I view as the three important takeaways from the hard work Tech Solidarity put into&#xa0;<a href=\"https://techsolidarity.org/resources.html\" rel=\"noopener noreferrer\">these resources</a>. These three short sentences are the 60 second summary of what you want to do, and what you want to share with others so&#xa0;<em>they</em>&#xa0;do, too.</p><p><strong>1) Enable Two Factor authentication through an app, and&#xa0;<em>not SMS</em>, everywhere you can.</strong></p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"481\" src=\"https://blog.codinghorror.com/content/images/2018/09/google-2fa-1.png\" width=\"566\" /></figure><p>Logging in with only a password, now matter how long and unique you attempt to make that password, will never be enough. A password is what you know; you need to add the second factor of something you&#xa0;<em>have</em>&#xa0;(or something you&#xa0;<em>are</em>) to achieve significant additional security. <a href=\"https://www.wired.com/story/phone-numbers-indentification-authentication/\" rel=\"noreferrer\">SMS can famously&#xa0;be intercepted</a>, social engineered, or sim-jacked all too easily. If it&#x2019;s SMS, it&#x2019;s not secure,&#xa0;<em>period</em>. So install an authenticator app, and use it, at least for your most important credentials such as your email account and your bank.</p><p>Have I mentioned that Discourse&#xa0;added <a href=\"https://blog.discourse.org/2018/05/discourse-2-0-released/\" rel=\"noopener noreferrer\">two factor authentication support</a> in version 2.0, and our just released 2.1 adds printed backup codes, too? There are two paths forward: you can&#xa0;<em>talk</em>&#xa0;about the solution, or you can&#xa0;<em>build</em>&#xa0;the solution. I&#x2019;m trying to do both to the best of my ability. Look for the 2FA auth option in your user preferences on your favorite Discourse instance. It&#x2019;s there for you.</p><p>(This is also a company policy at Discourse; if you work here,&#xa0;<em>you 2FA everything all the time</em>. No other login option exists.)</p><p><strong>2) Make all your passwords 11 characters or more.</strong></p><p>It&#x2019;s <a href=\"https://blog.codinghorror.com/hacker-hack-thyself/\">a long story</a>, but anything under 11 characters&#xa0;is basically the <a href=\"https://blog.codinghorror.com/your-password-is-too-damn-short/\" rel=\"noreferrer\">same as having no password</a> at all&#xa0;these days. I personally recommend at least 14 characters, maybe even 16. But this won&#x2019;t be a problem for you, because...</p><p><strong>3) Use a password manager.</strong></p><p>If you use a password manager, you can simultaneously avoid the pernicious danger of password re-use and&#xa0;the difficulty of coming up with <a href=\"https://blog.codinghorror.com/password-rules-are-bullshit/\">unique and random passwords</a>&#xa0;all the time. It is my hope in the long run that cloud based password management gets deeply built into Android, iOS, OSX, and Windows so that people don&#x2019;t need to run a weird m&#xe9;lange of third party apps to achieve this essential task. Password management is foundational and should not be the province of third parties on principle, because you never outsource a core competency.</p><p><strong>Bonus rule! For the particularly at-risk, get and use a U2F key.</strong></p><p>In the long term, two factor through an app isn&#x2019;t quite secure enough due to the very real (and growing) specter of real-time phishing. Authentication apps offer timed keys that expire after a minute or two, but if the attacker can get you to type an authentication key and relay it to the target site fast enough, they can still log in as you. If you need ultimate protection,&#xa0;look into <a href=\"https://en.wikipedia.org/wiki/Universal_2nd_Factor\" rel=\"noopener noreferrer\">U2F keys</a>.</p><figure class=\"kg-card kg-image-card\"><img alt=\"There is no longer any such thing as Computer Security\" class=\"kg-image\" height=\"720\" src=\"https://blog.codinghorror.com/content/images/2018/09/u2f-keys.jpg\" width=\"720\" /></figure><p>I believe U2F support is still too immature at the moment, particularly on mobile, for this to be practical for the average person right now. But if you do happen to fall into those groups that will be under attack, you&#xa0;<em>absolutely</em>&#xa0;want to set up U2F keys where you can today. They&#x2019;re cheap, and the good news is that they&#xa0;<em>literally make phishing impossible</em>&#xa0;at last. Given that Google had&#xa0;100% company-wide <a href=\"https://krebsonsecurity.com/2018/07/google-security-keys-neutralized-employee-phishing/\" rel=\"noopener noreferrer\">success against phishing with U2F</a>, we know this works.</p><p>In today&#x2019;s world, computers are now so omnipresent that there is no longer any such thing as cybersecurity, online security, or computer security &#x2013; there&#x2019;s only&#xa0;<em>security</em>. You either have it, or you don&#x2019;t. If you follow and share these three rules, hopefully you too can have a modicum of security today.</p>",
      "tier": "trending",
      "selection_reason": "Provocative perspective on future of security",
      "audience_value": "Strategic implications for tech development",
      "urgency_score": 8,
      "category_tag": "\ud83d\udd10 Security"
    },
    {
      "id": "3ed7b713687f5a31bc520ddd1facea0a",
      "title": "WordPress.com adds an AI Assistant that can edit, adjust styles, create images, and more",
      "url": "https://techcrunch.com/2026/02/17/wordpress-com-adds-an-ai-assistant-that-can-edit-adjust-styles-create-images-and-more/",
      "published_date": "2026-02-19T06:59:32.492346",
      "description": "The feature is designed to work inside the website to understand its content and layout, allowing site owners to make changes with natural language commands. The WordPress AI assistant doesn't need precisely tailored prompts, either.",
      "source": "AI News & Artificial Intelligence | TechCrunch",
      "category": "Emerging Tech",
      "segment": "innovators",
      "source_type": "secondary",
      "raw_content": "The feature is designed to work inside the website to understand its content and layout, allowing site owners to make changes with natural language commands. The WordPress AI assistant doesn't need precisely tailored prompts, either.",
      "tier": "trending",
      "selection_reason": "Major platform adding AI capabilities",
      "audience_value": "Insights into AI integration trends",
      "urgency_score": 7,
      "category_tag": "\ud83d\ude80 AI & Innovation"
    }
  ]
}